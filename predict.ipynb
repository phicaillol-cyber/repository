{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phicaillol-cyber/repository/blob/main/predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset creation"
      ],
      "metadata": {
        "id": "c-sdParCMe8G"
      },
      "id": "c-sdParCMe8G"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a59ae70c-0532-4cf6-ac10-38d606068a6e",
      "metadata": {
        "id": "a59ae70c-0532-4cf6-ac10-38d606068a6e",
        "outputId": "63a03c46-71c6-44e9-9f94-cab663208829",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[**********************85%****************       ]  111 of 131 completedERROR:yfinance:HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: CDXBTC-USD\"}}}\n",
            "[*********************100%***********************]  131 of 131 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['CDXBTC-USD']: YFTzMissingError('possibly delisted; no timezone found')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (710, 132)\n",
            "Ticker       date      AAPL      ABBV       ABT    ACA.PA       ACN      ADBE  \\\n",
            "0      2023-05-12 -0.541764  0.382007  0.399803  1.436981  1.807030 -1.794594   \n",
            "1      2023-05-15 -0.289737 -0.380553 -0.588287 -0.341353  0.115445  3.046654   \n",
            "2      2023-05-16  0.000000 -2.251164 -0.409686  0.428143  0.605376 -0.162012   \n",
            "3      2023-05-17  0.360318  0.041890 -0.521075 -0.289895  1.948495  3.338072   \n",
            "4      2023-05-18  1.366610  0.062750 -0.321621  0.991965  1.001301  1.065527   \n",
            "\n",
            "Ticker       ADI     AI.PA    AIR.PA  ...      ^DJI      ^FVX      ^IRX  \\\n",
            "0      -0.011066  0.602252  1.219916  ... -0.026691  2.738911  0.259223   \n",
            "1       2.104438 -0.118185  0.211726  ...  0.144083  0.521592 -0.556879   \n",
            "2      -0.856978 -0.635285  2.584107  ... -1.008921  1.527817  1.160002   \n",
            "3       2.828393  0.037619  1.552598  ...  1.237814  1.987505  0.593115   \n",
            "4       2.287729  1.065162  0.468019  ...  0.344518  2.951001  0.727205   \n",
            "\n",
            "Ticker      ^NDX  ^SP500-15  ^SP500-20  ^STOXX50E      ^TNX      ^TYX  \\\n",
            "0      -0.370436   0.171187   0.010811   0.188639  1.942890  0.773747   \n",
            "1       0.549693   0.846338   0.507069  -0.034038  1.299447  1.720944   \n",
            "2       0.093190  -1.644172  -1.362889  -0.020860  1.168761  0.754816   \n",
            "3       1.215923   0.666612   1.700486   0.178895  0.901664  0.180831   \n",
            "4       1.805546   0.548096   0.667387        NaN  1.870983  0.593089   \n",
            "\n",
            "Ticker      ^VIX  \n",
            "0       0.590670  \n",
            "1       0.528480  \n",
            "2       5.081769  \n",
            "3      -6.225675  \n",
            "4      -4.860709  \n",
            "\n",
            "[5 rows x 132 columns]\n",
            "Ticker       date      AAPL      ABBV       ABT    ACA.PA       ACN      ADBE  \\\n",
            "705    2026-01-29  0.717515  0.804863  0.037712  0.444444 -3.405684 -2.647037   \n",
            "706    2026-01-30  0.464617  1.170440  3.025739  1.050888  0.926427  0.548605   \n",
            "707    2026-02-02  4.058116  1.179322  0.100641  1.149420  1.194809  0.044332   \n",
            "708    2026-02-03 -0.196289  0.008866 -0.356464  1.433990 -9.588066 -7.311341   \n",
            "709    2026-02-04  2.426933 -6.602858 -0.440282       NaN  1.513202  2.936423   \n",
            "\n",
            "Ticker       ADI     AI.PA    AIR.PA  ...      ^DJI      ^FVX      ^IRX  \\\n",
            "705     0.336872  0.815805 -0.543421  ...  0.114162 -0.963039 -0.055837   \n",
            "706    -2.453720 -0.151720 -0.309281  ... -0.364957 -0.210253 -0.223461   \n",
            "707     1.923565  0.949728  0.206830  ...  1.053723  1.000793  0.167974   \n",
            "708    -1.757867  0.025084 -1.836944  ... -0.337340  0.052147  0.335379   \n",
            "709     0.984613       NaN       NaN  ...  0.620926 -0.286686  0.222845   \n",
            "\n",
            "Ticker      ^NDX  ^SP500-15  ^SP500-20  ^STOXX50E      ^TNX      ^TYX  \\\n",
            "705    -0.532181   0.141751   1.016677  -0.695240 -0.564566 -0.123458   \n",
            "706    -1.282284  -1.844946  -0.277070   0.948071  0.331203  0.370831   \n",
            "707     0.728772   0.711470   1.259241   1.003726  0.801696  0.759436   \n",
            "708    -1.554048   2.001594   0.893708  -0.202408 -0.023390 -0.061108   \n",
            "709    -1.570871   1.360200   0.060824        NaN -0.070198  0.101918   \n",
            "\n",
            "Ticker       ^VIX  \n",
            "705      3.241583  \n",
            "706      3.317544  \n",
            "707     -6.307341  \n",
            "708     10.159118  \n",
            "709      8.611107  \n",
            "\n",
            "[5 rows x 132 columns]\n",
            "NaN par colonne :\n",
            "Ticker\n",
            "CDXBTC-USD    710\n",
            "^CIISCSEP     710\n",
            "FISV           52\n",
            "ABT            50\n",
            "ABBV           50\n",
            "AAPL           50\n",
            "ADI            50\n",
            "ASML           50\n",
            "AMZN           50\n",
            "AMGN           50\n",
            "ACN            50\n",
            "AVGO           50\n",
            "BAC            50\n",
            "BKNG           50\n",
            "CSCO           50\n",
            "dtype: int64\n",
            "Creation de CAC40_TICKERS.csv et du dataset DATASET_1000DAYS_VARIATION.csv terminée: \n",
            "2026-02-04 17:03:55.225617\n"
          ]
        }
      ],
      "source": [
        "### Creation du dataset de variation des tickers des 1000 derniers jours\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Définir la période de 1000 jours\n",
        "end_date = datetime.now()\n",
        "start_date = end_date - timedelta(days=1000)\n",
        "\n",
        "# Liste des tickers du CAC 40 (exemple : 'OR.PA' pour L'Oréal)\n",
        "cac40_tickers = cac40_tickers = [\n",
        "    \"AI.PA\",   # Air Liquide\n",
        "    \"AIR.PA\",  # Airbus\n",
        "    \"ALO.PA\",  # Alstom\n",
        "    \"CS.PA\",   # AXA\n",
        "    \"BNP.PA\",  # BNP Paribas\n",
        "    \"EN.PA\",   # Bouygues\n",
        "    \"CAP.PA\",  # Capgemini\n",
        "    \"CA.PA\",   # Carrefour\n",
        "    \"ACA.PA\",  # Crédit Agricole\n",
        "    \"BN.PA\",   # Danone\n",
        "    \"DSY.PA\",  # Dassault Systèmes\n",
        "    \"EDEN.PA\", # Edenred\n",
        "    \"ENGI.PA\", # Engie\n",
        "    \"EL.PA\",   # EssilorLuxottica\n",
        "    \"ERF.PA\",  # Eurofins Scientific\n",
        "    \"RMS.PA\",  # Hermès\n",
        "    \"KER.PA\",  # Kering\n",
        "    \"LR.PA\",   # Legrand\n",
        "    \"OR.PA\",   # L'Oréal\n",
        "    \"MC.PA\",   # LVMH\n",
        "    \"ML.PA\",   # Michelin\n",
        "    \"ORA.PA\",  # Orange\n",
        "    \"RI.PA\",   # Pernod Ricard\n",
        "    \"PUB.PA\",  # Publicis\n",
        "    \"RNO.PA\",  # Renault\n",
        "    \"SAF.PA\",  # Safran\n",
        "    \"SGO.PA\",  # Saint-Gobain\n",
        "    \"SAN.PA\",  # Sanofi\n",
        "    \"SU.PA\",   # Schneider Electric\n",
        "    \"GLE.PA\",  # Société Générale\n",
        "    \"TEP.PA\",  # Teleperformance\n",
        "    \"HO.PA\",   # Thales\n",
        "    \"TTE.PA\",  # TotalEnergies\n",
        "    \"URW.PA\",  # Unibail-Rodamco-Westfield\n",
        "    \"VIE.PA\",  # Veolia\n",
        "    \"DG.PA\",   # Vinci\n",
        "    \"VIV.PA\",  # Vivendi\n",
        "    \"WLN.PA\"   # Worldline\n",
        "]\n",
        "\n",
        "# Liste des tickers du NASDAQ (exemple : 'AAPL' pour Apple)\n",
        "nasdaq_tickers = nasdaq_top_40 = [\n",
        "    \"AAPL\",  # Apple\n",
        "    \"MSFT\",  # Microsoft\n",
        "    \"GOOGL\", # Alphabet (Google)\n",
        "    \"AMZN\",  # Amazon\n",
        "    \"META\",  # Meta (Facebook)\n",
        "    \"NVDA\",  # NVIDIA\n",
        "    \"TSLA\",  # Tesla\n",
        "    \"AVGO\",  # Broadcom\n",
        "    \"PEP\",   # PepsiCo\n",
        "    \"COST\",  # Costco\n",
        "    \"ADBE\",  # Adobe\n",
        "    \"NFLX\",  # Netflix\n",
        "    \"PYPL\",  # PayPal\n",
        "    \"INTC\",  # Intel\n",
        "    \"CSCO\",  # Cisco\n",
        "    \"CMCSA\", # Comcast\n",
        "    \"AMGN\",  # Amgen\n",
        "    \"TXN\",   # Texas Instruments\n",
        "    \"QCOM\",  # Qualcomm\n",
        "    \"HON\",   # Honeywell\n",
        "    \"AMD\",   # Advanced Micro Devices (AMD)\n",
        "    \"ISRG\",  # Intuitive Surgical\n",
        "    \"SBUX\",  # Starbucks\n",
        "    \"MDLZ\",  # Mondelēz\n",
        "    \"AMAT\",  # Applied Materials\n",
        "    \"LRCX\",  # Lam Research\n",
        "    \"ADI\",   # Analog Devices\n",
        "    \"MU\",    # Micron Technology\n",
        "    \"ASML\", # ASML Holding\n",
        "    \"MRNA\", # Moderna\n",
        "    \"ILMN\",  # Illumina\n",
        "    \"BKNG\",  # Booking Holdings\n",
        "    \"REGN\",  # Regeneron\n",
        "    \"KDP\",   # Keurig Dr Pepper\n",
        "    \"MNST\",  # Monster Beverage\n",
        "    \"FISV\",  # Fiserv\n",
        "    \"WDAY\",  # Workday\n",
        "    \"TEAM\"   # Atlassian\n",
        "]\n",
        "\n",
        "nyse_tickers = nyse_top_40 = [\n",
        "    \"XOM\",   # Exxon Mobil\n",
        "    \"JNJ\",   # Johnson & Johnson\n",
        "    \"V\",     # Visa\n",
        "    \"PG\",    # Procter & Gamble\n",
        "    \"MA\",    # Mastercard\n",
        "    \"HD\",    # Home Depot\n",
        "    \"DIS\",   # Disney\n",
        "    \"VZ\",    # Verizon\n",
        "    \"MCD\",   # McDonald's\n",
        "    \"CVX\",   # Chevron\n",
        "    \"WMT\",   # Walmart\n",
        "    \"BAC\",   # Bank of America\n",
        "    \"PFE\",   # Pfizer\n",
        "    \"KO\",    # Coca-Cola\n",
        "    \"MRK\",   # Merck\n",
        "    \"ABBV\",  # AbbVie\n",
        "    \"CRM\",   # Salesforce\n",
        "    \"ABT\",   # Abbott Laboratories\n",
        "    \"PEP\",   # PepsiCo\n",
        "    \"C\",     # Citigroup\n",
        "    \"TMO\",   # Thermo Fisher Scientific\n",
        "    \"LIN\",   # Linde\n",
        "    \"CSCO\",  # Cisco (aussi coté sur NYSE)\n",
        "    \"ACN\",   # Accenture\n",
        "    \"CVS\",   # CVS Health\n",
        "    \"ORCL\",  # Oracle\n",
        "    \"NKE\",   # Nike\n",
        "    \"LLY\",   # Eli Lilly\n",
        "    \"DHR\",   # Danaher\n",
        "    \"UNH\",   # UnitedHealth\n",
        "    \"PM\",    # Philip Morris\n",
        "    \"IBM\",   # IBM\n",
        "    \"MMM\",   # 3M\n",
        "    \"MDT\",   # Medtronic\n",
        "    \"GE\",    # General Electric\n",
        "    \"GS\",    # Goldman Sachs\n",
        "    \"CAT\",   # Caterpillar\n",
        "    \"RTX\",   # Raytheon Technologies\n",
        "    \"UPS\",   # UPS\n",
        "    \"MO\",    # Altria\n",
        "]\n",
        "\n",
        "# Inclure également les indices macro (VIX, Dollar Index, Brent, Or)\n",
        "macro_tickers = [\n",
        "    \"GC=F\",        # Or (Gold Futures COMEX)\n",
        "    \"BZ=F\",        # Pétrole Brent (Brent Crude Oil Futures)\n",
        "    \"^NDX\",        # NASDAQ 100 (technologie US, croissance)\n",
        "    \"^DJI\",        # Dow Jones Industrial Average (blue chips US)\n",
        "    \"^SP500-20\",   # S&P 500 Industrials (secteur industriel)\n",
        "    \"^SP500-15\",   # S&P 500 Materials (matières premières)\n",
        "    \"^STOXX50E\",   # Euro STOXX 50 (grandes capitalisations zone euro)\n",
        "    \"DX-Y.NYB\",    # Dollar Index (DXY – force du dollar US)\n",
        "    \"EUR=X\",       # Taux de change EUR/USD\n",
        "    \"CHF=X\",       # Taux de change USD/CHF (valeur refuge)\n",
        "    \"^VIX\",        # Indice de volatilité (peur / stress de marché)\n",
        "    \"^IRX\",        # Taux US 13 semaines (T-Bills court terme)\n",
        "    \"^FVX\",        # Taux US 5 ans\n",
        "    \"^TNX\",        # Taux US 10 ans (benchmark macro mondial)\n",
        "    \"^TYX\",        # Taux US 30 ans (long terme)\n",
        "    \"^CIISCSEP\",   # Indice de surprises économiques Citi (US)\n",
        "    \"CDX\"          # Indice de crédit (Credit Default Swaps – stress crédit)\n",
        "    \"BTC-USD\"      # Bitcoin\n",
        "]\n",
        "\n",
        "\n",
        "# Combiner toutes les listes de tickers\n",
        "all_tickers = cac40_tickers + nasdaq_tickers + nyse_tickers + macro_tickers\n",
        "\n",
        "# Télécharger les données boursières\n",
        "data = yf.download(all_tickers, start=start_date, end=end_date,auto_adjust=True)\n",
        "\n",
        "# Calculer la variation en pourcentage par rapport à la clôture précédente\n",
        "variation = data[\"Close\"].pct_change(fill_method=None) * 100\n",
        "variation = variation.dropna(how=\"all\")\n",
        "\n",
        "variation.index = pd.to_datetime(variation.index)\n",
        "variation.index.name = \"date\"\n",
        "\n",
        "dataset_ts = variation.reset_index()\n",
        "dataset_ts = dataset_ts.sort_values(\"date\")\n",
        "\n",
        "print(\"Shape:\", dataset_ts.shape)\n",
        "print(dataset_ts.head())\n",
        "print(dataset_ts.tail())\n",
        "print(\"NaN par colonne :\")\n",
        "print(variation.isna().sum().sort_values(ascending=False).head(15))\n",
        "\n",
        "pd.DataFrame(cac40_tickers, columns=[\"Ticker\"]).to_csv(\"CAC40_TICKERS.csv\", index=False)\n",
        "dataset_ts.to_csv(\"DATASET_1000DAYS_VARIATION.csv\", index=False)\n",
        "\n",
        "now = datetime.now()\n",
        "print(\"Creation de CAC40_TICKERS.csv et du dataset DATASET_1000DAYS_VARIATION.csv terminée: \")\n",
        "print(now)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# rules detection"
      ],
      "metadata": {
        "id": "AAME67UIp6Oc"
      },
      "id": "AAME67UIp6Oc"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from itertools import combinations\n",
        "\n",
        "# =========================\n",
        "# 1. Chargement des données\n",
        "# =========================\n",
        "\n",
        "# Adapter le chemin si nécessaire\n",
        "FILE_PATH = \"DATASET_1000DAYS_VARIATION.csv\"\n",
        "\n",
        "df = pd.read_csv(FILE_PATH)\n",
        "df = df.drop(columns=[\"date\"])\n",
        "\n",
        "# =========================\n",
        "# 2. Discrétisation\n",
        "# =========================\n",
        "\n",
        "def discretize(x):\n",
        "    if x > 1.0:\n",
        "        return \"UP\"\n",
        "    elif x < -1.0:\n",
        "        return \"DOWN\"\n",
        "    else:\n",
        "        return \"NEUTRAL\"\n",
        "\n",
        "disc = df.applymap(discretize)\n",
        "\n",
        "# =========================\n",
        "# 3. Détection des règles\n",
        "# =========================\n",
        "\n",
        "def mine_lead_rules(\n",
        "    disc,\n",
        "    min_support=0.03,\n",
        "    min_confidence=0.60,\n",
        "    min_lift=1.40\n",
        "):\n",
        "    rules = []\n",
        "\n",
        "    for target in disc.columns:\n",
        "        future = disc[target].shift(-1)\n",
        "        base_rate = (future == \"UP\").mean()\n",
        "\n",
        "        # On ignore les cibles trop rares\n",
        "        if base_rate < 0.05:\n",
        "            continue\n",
        "\n",
        "        leaders = [c for c in disc.columns if c != target]\n",
        "\n",
        "        for l1, l2 in combinations(leaders, 2):\n",
        "\n",
        "            # Condition à t\n",
        "            mask = (\n",
        "                (disc[l1] == \"UP\") &\n",
        "                (disc[l2] == \"DOWN\")\n",
        "            )\n",
        "\n",
        "            support = mask.mean()\n",
        "            if support < min_support:\n",
        "                continue\n",
        "\n",
        "            confidence = (future[mask] == \"UP\").mean()\n",
        "            if confidence < min_confidence:\n",
        "                continue\n",
        "\n",
        "            lift = confidence / base_rate\n",
        "            if lift < min_lift:\n",
        "                continue\n",
        "\n",
        "            rules.append({\n",
        "                \"target\": target,\n",
        "                \"leaders\": f\"{l1} ↑ AND {l2} ↓\",\n",
        "                \"support\": round(support, 3),\n",
        "                \"confidence\": round(confidence, 3),\n",
        "                \"lift\": round(lift, 2)\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(rules)\n",
        "\n",
        "# =========================\n",
        "# 4. Exécution\n",
        "# =========================\n",
        "\n",
        "rules = mine_lead_rules(disc)\n",
        "\n",
        "rules = rules.sort_values(\n",
        "    by=[\"lift\", \"confidence\"],\n",
        "    ascending=False\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# 5. Résultats\n",
        "# =========================\n",
        "\n",
        "print(\"\\nTop 20 règles détectées :\\n\")\n",
        "print(rules.head(20))\n",
        "\n",
        "# Optionnel : sauvegarde\n",
        "rules.to_csv(\"lead_lag_rules_results.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "tTulpFIuqE4F",
        "outputId": "a3c9091d-8df9-4067-a722-eca00801dfa9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "tTulpFIuqE4F",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1273723006.py:27: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  disc = df.applymap(discretize)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross correlation Lead–Lag multivarié (Lasso)"
      ],
      "metadata": {
        "id": "BdSnwSI0IB7W"
      },
      "id": "BdSnwSI0IB7W"
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# LEAD–LAG MULTIVARIÉ PAR LASSO (SCRIPT COMPLET)\n",
        "# ============================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# 1. CHARGEMENT DU DATASET\n",
        "# ----------------------------\n",
        "FILE_PATH = \"DATASET_1000DAYS_VARIATION.csv\"\n",
        "\n",
        "df = pd.read_csv(FILE_PATH)\n",
        "\n",
        "# gestion de la date\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df = df.set_index('date')\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# 2. NETTOYAGE & SÉCURITÉS\n",
        "# ----------------------------\n",
        "\n",
        "# garder uniquement les colonnes numériques\n",
        "df = df.select_dtypes(include=[np.number])\n",
        "\n",
        "if df.shape[1] == 0:\n",
        "    raise ValueError(\"Aucune colonne numérique exploitable\")\n",
        "\n",
        "# conserver les séries suffisamment complètes (au moins 80% des lignes présentes)\n",
        "threshold = int(len(df) * 0.8)\n",
        "df = df.dropna(axis=1, thresh=threshold)\n",
        "\n",
        "# supprimer les lignes avec NaN restantes\n",
        "df = df.dropna()\n",
        "\n",
        "if df.empty:\n",
        "    raise ValueError(\"Dataset vide après nettoyage. Essayez de réduire le threshold ou de vérifier la source des données.\")\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# 3. STANDARDISATION\n",
        "# ----------------------------\n",
        "scaler = StandardScaler()\n",
        "\n",
        "df_scaled = pd.DataFrame(\n",
        "    scaler.fit_transform(df.values),\n",
        "    index=df.index,\n",
        "    columns=df.columns\n",
        ")\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# 4. CONSTRUCTION DES LAGS\n",
        "# ----------------------------\n",
        "def build_lagged_matrix(df, max_lag):\n",
        "    X = []\n",
        "    feature_names = []\n",
        "\n",
        "    for lag in range(1, max_lag + 1):\n",
        "        shifted = df.shift(lag)\n",
        "        X.append(shifted.values)\n",
        "\n",
        "        for col in df.columns:\n",
        "            feature_names.append(f\"{col}_lag{lag}\")\n",
        "\n",
        "    X = np.hstack(X)\n",
        "    return X, feature_names\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# 5. LASSO MULTIVARIÉ LEAD–LAG\n",
        "# ----------------------------\n",
        "def multivariate_lead_lag_lasso(df, target, max_lag=5, min_coef=1e-4):\n",
        "    X, feature_names = build_lagged_matrix(df, max_lag)\n",
        "    y = df[target].values\n",
        "\n",
        "    # alignement temporel\n",
        "    X = X[max_lag:]\n",
        "    y = y[max_lag:]\n",
        "\n",
        "    model = LassoCV(\n",
        "        cv=5,\n",
        "        max_iter=5000,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    model.fit(X, y)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for coef, fname in zip(model.coef_, feature_names):\n",
        "        if abs(coef) >= min_coef:\n",
        "            col, lag = fname.rsplit(\"_lag\", 1)\n",
        "            results.append({\n",
        "                \"target\": target,\n",
        "                \"leader\": col,\n",
        "                \"lag_days\": int(lag),\n",
        "                \"coefficient\": coef\n",
        "            })\n",
        "\n",
        "    # Gestion du cas où aucun coefficient n'est retenu (évite KeyError)\n",
        "    if not results:\n",
        "        return pd.DataFrame(columns=[\"target\", \"leader\", \"lag_days\", \"coefficient\"])\n",
        "\n",
        "    return pd.DataFrame(results).sort_values(\n",
        "        by=\"coefficient\",\n",
        "        key=np.abs,\n",
        "        ascending=False\n",
        "    )\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# 6. LANCEMENT GLOBAL\n",
        "# ----------------------------\n",
        "MAX_LAG = 5\n",
        "all_results = []\n",
        "\n",
        "for target in df_scaled.columns:\n",
        "    res = multivariate_lead_lag_lasso(\n",
        "        df_scaled,\n",
        "        target=target,\n",
        "        max_lag=MAX_LAG\n",
        "    )\n",
        "\n",
        "    if not res.empty:\n",
        "        all_results.append(res)\n",
        "\n",
        "if not all_results:\n",
        "    print(\"Aucun lead-lag significatif trouvé.\")\n",
        "    best_results = pd.DataFrame()\n",
        "else:\n",
        "    final_results = pd.concat(all_results, ignore_index=True)\n",
        "\n",
        "    # ----------------------------\n",
        "    # 7. RÉSULTATS FINAUX\n",
        "    # ----------------------------\n",
        "    best_results = final_results.sort_values(\n",
        "        by=\"coefficient\",\n",
        "        key=np.abs,\n",
        "        ascending=False\n",
        "    )\n",
        "\n",
        "    print(best_results.head(20))\n",
        "\n",
        "    # ----------------------------\n",
        "    # 8. EXPORT OPTIONNEL\n",
        "    # ----------------------------\n",
        "    best_results.to_csv(\n",
        "        \"multivariate_lead_lag_lasso_results.csv\",\n",
        "        index=False\n",
        "    )\n",
        "\n",
        "# ============================================================\n",
        "# FIN DU SCRIPT\n",
        "# ============================================================"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6SeFQr3H8PV",
        "outputId": "6d1935d0-9a09-45de-ce84-332ef62c23d6"
      },
      "id": "j6SeFQr3H8PV",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.569e-02, tolerance: 3.353e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.234e-02, tolerance: 5.319e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.059e-02, tolerance: 5.319e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.785e-02, tolerance: 5.319e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.211e-02, tolerance: 4.742e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.823e-02, tolerance: 4.742e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.562e-02, tolerance: 4.727e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.488e-02, tolerance: 4.355e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.468e-02, tolerance: 5.025e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.311e-02, tolerance: 5.492e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.804e-02, tolerance: 5.280e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.747e-02, tolerance: 5.280e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.403e-02, tolerance: 4.790e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.633e-02, tolerance: 5.568e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.114e-02, tolerance: 4.821e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.579e-02, tolerance: 5.275e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.723e-02, tolerance: 4.621e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.750e-02, tolerance: 5.457e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.771e-02, tolerance: 4.877e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.635e-02, tolerance: 4.877e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.959e-02, tolerance: 5.471e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.784e-02, tolerance: 5.471e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.567e-02, tolerance: 5.471e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.015e-02, tolerance: 5.471e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.957e-02, tolerance: 4.561e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.911e-02, tolerance: 4.561e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.662e-02, tolerance: 4.561e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.974e-02, tolerance: 4.789e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.145e-02, tolerance: 4.789e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.489e-02, tolerance: 5.351e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.923e-02, tolerance: 5.308e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.567e-02, tolerance: 4.212e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.518e-02, tolerance: 4.212e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.696e-02, tolerance: 4.751e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.626e-02, tolerance: 5.261e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.132e-02, tolerance: 4.751e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.673e-02, tolerance: 5.291e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.058e-02, tolerance: 5.291e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.409e-02, tolerance: 5.291e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.178e-02, tolerance: 4.975e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.438e-02, tolerance: 4.975e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.982e-02, tolerance: 4.975e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.441e-02, tolerance: 4.975e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.619e-02, tolerance: 5.106e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.357e-02, tolerance: 5.106e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.147e-02, tolerance: 5.106e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.016e-02, tolerance: 5.564e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.365e-02, tolerance: 5.202e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.844e-02, tolerance: 5.202e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.332e-02, tolerance: 4.757e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.224e-02, tolerance: 4.757e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.885e-02, tolerance: 5.286e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.524e-02, tolerance: 5.330e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.836e-02, tolerance: 5.439e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.469e-02, tolerance: 5.295e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.558e-02, tolerance: 5.295e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.172e-02, tolerance: 5.043e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.968e-02, tolerance: 4.903e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.326e-02, tolerance: 5.181e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.411e-02, tolerance: 4.622e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.387e-02, tolerance: 5.329e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.985e-02, tolerance: 5.155e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.531e-02, tolerance: 5.155e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.622e-02, tolerance: 5.155e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.109e-02, tolerance: 5.155e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.465e-02, tolerance: 5.155e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.404e-02, tolerance: 5.574e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.909e-02, tolerance: 4.919e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.283e-02, tolerance: 4.822e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.726e-02, tolerance: 5.349e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.513e-02, tolerance: 5.340e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.202e-02, tolerance: 4.991e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.618e-02, tolerance: 4.303e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.115e-02, tolerance: 4.303e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.329e-02, tolerance: 4.952e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.761e-02, tolerance: 5.198e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.437e-02, tolerance: 5.163e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.407e-02, tolerance: 4.915e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.018e-02, tolerance: 5.548e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.769e-02, tolerance: 5.555e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.746e-02, tolerance: 5.372e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.573e-02, tolerance: 5.404e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.483e-02, tolerance: 5.101e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.247e-02, tolerance: 5.246e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.002e-02, tolerance: 5.246e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.768e-02, tolerance: 5.246e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.261e-02, tolerance: 5.246e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.560e-02, tolerance: 5.246e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.323e-02, tolerance: 5.246e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.833e-02, tolerance: 4.745e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.024e-02, tolerance: 4.745e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.008e-02, tolerance: 4.745e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.812e-02, tolerance: 5.718e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.159e-02, tolerance: 4.408e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.976e-02, tolerance: 5.627e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.767e-02, tolerance: 5.627e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.179e-02, tolerance: 5.627e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.319e-02, tolerance: 5.627e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.881e-02, tolerance: 5.627e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.610e-02, tolerance: 5.327e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.167e-02, tolerance: 4.640e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.929e-02, tolerance: 4.640e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.126e-02, tolerance: 4.640e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.706e-02, tolerance: 5.681e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.416e-02, tolerance: 5.681e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.911e-02, tolerance: 5.681e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.666e-02, tolerance: 5.637e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.670e-02, tolerance: 5.637e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     target     leader  lag_days  coefficient\n",
            "160   EUR=X   DX-Y.NYB         1     0.782119\n",
            "98    CHF=X   DX-Y.NYB         1     0.587241\n",
            "303  SGO.PA        UPS         5    -0.113152\n",
            "91   CAP.PA        ACN         1     0.112401\n",
            "304  SGO.PA  ^SP500-20         1     0.109580\n",
            "26    AI.PA        RTX         1     0.093911\n",
            "242    MSFT      MC.PA         1     0.087892\n",
            "336  TEP.PA       ADBE         1     0.072979\n",
            "190  GLE.PA       PYPL         2    -0.072210\n",
            "27    AI.PA        LIN         1     0.071137\n",
            "161   EUR=X      EUR=X         1    -0.069715\n",
            "375     XOM     SAF.PA         1     0.068024\n",
            "191  GLE.PA          C         1     0.065365\n",
            "413    ^IRX       FISV         3    -0.064903\n",
            "305  SGO.PA         GE         3     0.062498\n",
            "15     ADBE     VIV.PA         3     0.061980\n",
            "221      KO      DG.PA         2     0.061867\n",
            "82   BNP.PA  ^SP500-15         1     0.059958\n",
            "287    QCOM     DSY.PA         2    -0.059705\n",
            "28    AI.PA         GE         3     0.058266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lead Lag search"
      ],
      "metadata": {
        "id": "Z1jerT1XM-pP"
      },
      "id": "Z1jerT1XM-pP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d90c73b-74f4-4a70-8588-6a07e48a09a7",
      "metadata": {
        "id": "9d90c73b-74f4-4a70-8588-6a07e48a09a7"
      },
      "outputs": [],
      "source": [
        "### Recherche des leads/lags sur les actions du CAC40\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Charger le CSV\n",
        "dataset_ts = pd.read_csv(\n",
        "    \"DATASET_1000DAYS_VARIATION.csv\",\n",
        "    parse_dates=[\"date\"]   # très important\n",
        ")\n",
        "\n",
        "# Trier par date (sécurité)\n",
        "dataset_ts = dataset_ts.sort_values(\"date\")\n",
        "\n",
        "# Optionnel : remettre la date en index\n",
        "dataset_ts = dataset_ts.set_index(\"date\")\n",
        "\n",
        "def scan_lead_lag_cac40(\n",
        "    df,\n",
        "    cac40_cols,\n",
        "    other_cols,\n",
        "    max_lag=20,\n",
        "    min_obs=40,\n",
        "    method=\"pearson\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Scan exhaustif lead/lag entre :\n",
        "    - other_cols (X candidates)\n",
        "    - cac40_cols (Y targets)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "    \"\"\"\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for y in cac40_cols:\n",
        "        for x in other_cols:\n",
        "\n",
        "            if x == y:\n",
        "                continue\n",
        "\n",
        "            best_row = None\n",
        "\n",
        "            for lag in range(-max_lag, max_lag + 1):\n",
        "\n",
        "                if lag < 0:\n",
        "                    x_shifted = df[x].shift(-lag)\n",
        "                    y_shifted = df[y]\n",
        "                else:\n",
        "                    x_shifted = df[x]\n",
        "                    y_shifted = df[y].shift(lag)\n",
        "\n",
        "                pair = pd.concat([x_shifted, y_shifted], axis=1).dropna()\n",
        "\n",
        "                if len(pair) < min_obs:\n",
        "                    continue\n",
        "\n",
        "                corr = pair.iloc[:, 0].corr(pair.iloc[:, 1], method=method)\n",
        "\n",
        "                if pd.isna(corr):\n",
        "                    continue\n",
        "\n",
        "                row = {\n",
        "                    \"x\": x,\n",
        "                    \"y\": y,\n",
        "                    \"lag\": lag,\n",
        "                    \"correlation\": corr,\n",
        "                    \"abs_corr\": abs(corr),\n",
        "                    \"direction\": \"inverse\" if corr < 0 else \"same\",\n",
        "                    \"n_obs\": len(pair)\n",
        "                }\n",
        "\n",
        "                if best_row is None or row[\"abs_corr\"] > best_row[\"abs_corr\"]:\n",
        "                    best_row = row\n",
        "\n",
        "            if best_row is not None:\n",
        "                results.append(best_row)\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "df = dataset_ts\n",
        "cac40_cols = pd.read_csv(\"CAC40_TICKERS.csv\")['Ticker'].tolist()\n",
        "other_cols = [c for c in df.columns if c not in cac40_cols]\n",
        "\n",
        "results = scan_lead_lag_cac40(\n",
        "    df=df,\n",
        "    cac40_cols=cac40_cols,\n",
        "    other_cols=other_cols,\n",
        "    max_lag=20,\n",
        "    min_obs=40\n",
        ")\n",
        "\n",
        "results.sort_values(\"abs_corr\", ascending=False).head(20)\n",
        "results[\n",
        "    results[\"direction\"] == \"inverse\"\n",
        "].sort_values(\"abs_corr\", ascending=False).head(20)\n",
        "\n",
        "results[results[\"y\"] == \"MC.PA\"] \\\n",
        "    .sort_values(\"abs_corr\", ascending=False) \\\n",
        "    .head(10)\n",
        "\n",
        "print(\"Shape:\", results.shape)\n",
        "results.to_csv(\"LEAD_LAG_SCAN_CAC40.csv\", index=False)\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "now = datetime.now()\n",
        "print(\"Recherche des leads/lags sur les actions du CAC40 terminée: \")\n",
        "print(now)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Candidates selection"
      ],
      "metadata": {
        "id": "5rIc4-G4NG_T"
      },
      "id": "5rIc4-G4NG_T"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3b366ed8-1943-496d-a0dd-31c35f4ee81a"
      },
      "outputs": [],
      "source": [
        "### Recherche des variables candidates qui ont des leads/lags significatifs sur le CAC40\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# =========================\n",
        "# 1. CHARGEMENT DU CSV\n",
        "# =========================\n",
        "\n",
        "leadlag = pd.read_csv(\"LEAD_LAG_SCAN_CAC40.csv\")\n",
        "\n",
        "print(\"Dataset initial :\", leadlag.shape)\n",
        "\n",
        "# =========================\n",
        "# 2. FILTRE : LAG ≠ 0\n",
        "# =========================\n",
        "\n",
        "leadlag = leadlag[leadlag[\"lag\"] != 0]\n",
        "\n",
        "print(\"Après suppression lag = 0 :\", leadlag.shape)\n",
        "\n",
        "# =========================\n",
        "# 3. CLASSIFICATION DU RISQUE\n",
        "# =========================\n",
        "\n",
        "def classify_risk(abs_corr, n_obs):\n",
        "    if abs_corr >= 0.55 and n_obs >= 80:\n",
        "        return \"very_low_risk\"\n",
        "    elif abs_corr >= 0.45 and n_obs >= 60:\n",
        "        return \"low_risk\"\n",
        "    elif abs_corr >= 0.40 and n_obs >= 50:\n",
        "        return \"medium_risk\"\n",
        "    elif abs_corr >= 0.30 and n_obs >= 40:\n",
        "        return \"high_risk\"\n",
        "    else:\n",
        "        return \"very_high_risk\"\n",
        "\n",
        "leadlag[\"risk_level\"] = leadlag.apply(\n",
        "    lambda r: classify_risk(r[\"abs_corr\"], r[\"n_obs\"]),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# 4. TRI FINAL (DU + SÛR AU + RISQUÉ)\n",
        "# =========================\n",
        "\n",
        "risk_order = [\n",
        "    \"very_low_risk\",\n",
        "    \"low_risk\",\n",
        "    \"medium_risk\",\n",
        "    \"high_risk\",\n",
        "    \"very_high_risk\"\n",
        "]\n",
        "\n",
        "leadlag[\"risk_level\"] = pd.Categorical(\n",
        "    leadlag[\"risk_level\"],\n",
        "    categories=risk_order,\n",
        "    ordered=True\n",
        ")\n",
        "\n",
        "leadlag_sorted = leadlag.sort_values(\n",
        "    [\"risk_level\", \"abs_corr\"],\n",
        "    ascending=[True, False]\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# 5. CONTRÔLE RAPIDE\n",
        "# =========================\n",
        "\n",
        "print(\"\\nTop 20 relations les plus sûres (lag ≠ 0) :\")\n",
        "print(leadlag_sorted.head(20))\n",
        "\n",
        "# =========================\n",
        "# 6. SAUVEGARDE\n",
        "# =========================\n",
        "\n",
        "leadlag_sorted.to_csv(\n",
        "    \"LEAD_LAG_SCAN_CAC40_CLASSIFIED_LAG_NOT_ZERO.csv\",\n",
        "    index=False\n",
        ")\n",
        "\n",
        "print(\"\\nCSV sauvegardé : LEAD_LAG_SCAN_CAC40_CLASSIFIED_LAG_NOT_ZERO.csv\")\n",
        "\n",
        "# Charger le scan lead/lag\n",
        "leadlag = pd.read_csv(\"LEAD_LAG_SCAN_CAC40.csv\")\n",
        "\n",
        "# Filtre SAFE\n",
        "filtered = leadlag[\n",
        "    (leadlag[\"lag\"] != 0) &\n",
        "    (leadlag[\"abs_corr\"] >= 0.25) &\n",
        "    (leadlag[\"n_obs\"] >= 40)\n",
        "]\n",
        "\n",
        "# Extraire les candidats (variables X)\n",
        "candidatesX = (\n",
        "    filtered[\"x\"]\n",
        "    .value_counts()\n",
        "    .reset_index()\n",
        ")\n",
        "candidatesX.columns = [\"variable\", \"count\"]\n",
        "print(\"\\nCandidate variables\")\n",
        "print(candidatesX)\n",
        "pd.DataFrame(candidatesX, columns=[\"variable\"]).to_csv(\"CANDIDATES_VARIABLES.csv\", index=False)\n",
        "\n",
        "# Extraire les cibles (variables y)\n",
        "candidatesY = (\n",
        "    filtered[\"y\"]\n",
        "    .value_counts()\n",
        "    .reset_index()\n",
        ")\n",
        "candidatesY.columns = [\"variable\", \"count\"]\n",
        "print(\"\\nCandidate taget\")\n",
        "print(candidatesY)\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "now = datetime.now()\n",
        "print(\"Recherche des variables candidates CANDIDATES_VARIABLES.csv terminée: \")\n",
        "print(now)\n",
        "\n",
        "\n"
      ],
      "id": "3b366ed8-1943-496d-a0dd-31c35f4ee81a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Search best 2-3 variables combination"
      ],
      "metadata": {
        "id": "8LbcTNGrNYUz"
      },
      "id": "8LbcTNGrNYUz"
    },
    {
      "cell_type": "code",
      "source": [
        "### Meilleures correlations avec une combinaison de 3 variables max avec laf de 1 à 20 jours\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from itertools import combinations\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "# Charger le CSV\n",
        "dataset_ts = pd.read_csv(\n",
        "    \"DATASET_1000DAYS_VARIATION.csv\",\n",
        "    parse_dates=[\"date\"]   # très important\n",
        ")\n",
        "\n",
        "# Trier par date (sécurité)\n",
        "dataset_ts = dataset_ts.sort_values(\"date\")\n",
        "\n",
        "# Optionnel : remettre la date en index\n",
        "dataset_ts = dataset_ts.set_index(\"date\")\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "def composite_factor(df, cols):\n",
        "    X = df[list(cols)]\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = pd.DataFrame(\n",
        "        scaler.fit_transform(X),\n",
        "        index=X.index,\n",
        "        columns=cols\n",
        "    )\n",
        "    return X_scaled.mean(axis=1)\n",
        "\n",
        "def lead_corr(df, factor, target, lag, min_obs=60):\n",
        "    y = df[target].shift(-lag)\n",
        "    data = pd.concat([factor, y], axis=1).dropna()\n",
        "\n",
        "    if len(data) < min_obs:\n",
        "        return None\n",
        "\n",
        "    return data.iloc[:, 0].corr(data.iloc[:, 1])\n",
        "\n",
        "\n",
        "df = dataset_ts\n",
        "\n",
        "# Charger les candidats CSV\n",
        "#candidate_vars = pd.read_csv(\"CANDIDATES_VARIABLES.csv\")['variable'].tolist()\n",
        "candidate_vars = [\"^VIX\",\"^TNX\",\"GC=F\",\"BZ=F\",\"DX-Y.NYB\",\"^NDX\",\"AAPL\",\"^STOXX50E\",\"LIN\",\"ABBV\"]\n",
        "cac40_cols = pd.read_csv(\"CAC40_TICKERS.csv\")['Ticker'].tolist()\n",
        "\n",
        "from itertools import combinations\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def scan_all_cac40(\n",
        "    df,\n",
        "    cac40_cols,\n",
        "    candidate_vars,\n",
        "    lags=range(1, 20),\n",
        "    max_vars=3,\n",
        "    min_abs_corr=0.25,\n",
        "    min_obs=50\n",
        "):\n",
        "    results = []\n",
        "\n",
        "    for target in cac40_cols:\n",
        "\n",
        "        if target not in df.columns:\n",
        "            continue\n",
        "\n",
        "        for k in range(2, max_vars + 1):\n",
        "            for combo in combinations(candidate_vars, k):\n",
        "\n",
        "                try:\n",
        "                    factor = composite_factor(df, combo)\n",
        "                except Exception:\n",
        "                    continue\n",
        "\n",
        "                for lag in lags:\n",
        "                    corr = lead_corr(df, factor, target, lag, min_obs=min_obs)\n",
        "\n",
        "                    if corr is None or np.isnan(corr):\n",
        "                        continue\n",
        "\n",
        "                    abs_corr = abs(corr)\n",
        "\n",
        "                    if abs_corr < min_abs_corr:\n",
        "                        continue\n",
        "\n",
        "                    results.append({\n",
        "                        \"target\": target,\n",
        "                        \"variables\": combo,\n",
        "                        \"n_vars\": k,\n",
        "                        \"lag\": lag,\n",
        "                        \"correlation\": corr,\n",
        "                        \"abs_corr\": abs_corr,\n",
        "                        \"n_obs\": len(\n",
        "                            pd.concat(\n",
        "                                [factor, df[target].shift(-lag)],\n",
        "                                axis=1\n",
        "                            ).dropna()\n",
        "                        )\n",
        "                    })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "results_cac40 = scan_all_cac40(\n",
        "    df=dataset_ts,\n",
        "    cac40_cols=cac40_cols,\n",
        "    candidate_vars=candidate_vars,\n",
        "    lags=range(1, 20),\n",
        "    max_vars=3,\n",
        "    min_abs_corr=0.25\n",
        ")\n",
        "\n",
        "print(\"Shape :\", results_cac40.shape)\n",
        "print(\"Colonnes :\", results_cac40.columns)\n",
        "\n",
        "# Check if results_cac40 is empty before attempting to sort\n",
        "if not results_cac40.empty:\n",
        "    print(results_cac40.sort_values(\"abs_corr\", ascending=False).head(20))\n",
        "else:\n",
        "    print(\"No significant correlations found based on the given criteria.\")\n",
        "\n",
        "results_cac40.to_csv(\"BEST_PROBA.csv\", index=False)\n",
        "\n",
        "now = datetime.now()\n",
        "print(\"Résultat des meilleures probabilités BEST_PROBA.csv terminé: \")\n",
        "print(now)\n"
      ],
      "metadata": {
        "id": "W2w5klVCX8ct"
      },
      "id": "W2w5klVCX8ct",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CS.PA prediction historique for validation"
      ],
      "metadata": {
        "id": "Uij5aRPaK47h"
      },
      "id": "Uij5aRPaK47h"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# =========================\n",
        "# 1. CHARGEMENT DU DATASET\n",
        "# =========================\n",
        "\n",
        "df = pd.read_csv(\n",
        "    \"DATASET_1000DAYS_VARIATION.csv\",\n",
        "    parse_dates=[\"date\"]\n",
        ").set_index(\"date\")\n",
        "\n",
        "# On ne garde que les colonnes utiles\n",
        "df = df[[\"^NDX\", \"LIN\", \"ABBV\", \"CS.PA\"]].dropna()\n",
        "\n",
        "# =========================\n",
        "# 2. FEATURES & TARGET\n",
        "# =========================\n",
        "\n",
        "X = df[[\"^NDX\", \"LIN\", \"ABBV\"]]\n",
        "y = df[\"CS.PA\"].shift(-1)  # URW.PA à J+1\n",
        "\n",
        "data = pd.concat([X, y], axis=1).dropna()\n",
        "data.columns = [\"^NDX\", \"LIN\", \"ABBV\", \"CS_PRED_TARGET\"]\n",
        "\n",
        "# =========================\n",
        "# 3. WALK-FORWARD PREDICTION\n",
        "# =========================\n",
        "\n",
        "predictions = []\n",
        "\n",
        "MIN_TRAIN_SIZE = 60  # minimum historique pour entraîner\n",
        "\n",
        "for i in range(MIN_TRAIN_SIZE, len(data)):\n",
        "\n",
        "    train = data.iloc[:i]\n",
        "\n",
        "    X_train = sm.add_constant(train[[\"^NDX\", \"LIN\", \"ABBV\"]])\n",
        "    y_train = train[\"CS_PRED_TARGET\"]\n",
        "\n",
        "    model = sm.OLS(y_train, X_train).fit()\n",
        "\n",
        "    X_today = pd.DataFrame(\n",
        "        [data.iloc[i][[\"^NDX\", \"LIN\", \"ABBV\"]]],\n",
        "        columns=[\"^NDX\", \"LIN\", \"ABBV\"]\n",
        "    )\n",
        "\n",
        "    X_today = sm.add_constant(X_today, has_constant=\"add\")\n",
        "\n",
        "    pred = model.predict(X_today).iloc[0]\n",
        "\n",
        "    predictions.append(pred)\n",
        "\n",
        "# =========================\n",
        "# 4. AJOUT DE LA COLONNE DE PRÉDICTION\n",
        "# =========================\n",
        "\n",
        "# Aligner avec les dates\n",
        "pred_series = pd.Series(\n",
        "    predictions,\n",
        "    index=data.index[MIN_TRAIN_SIZE:],\n",
        "    name=\"CS.PA_PRED_TOMORROW\"\n",
        ")\n",
        "\n",
        "final_dataset = df.copy()\n",
        "final_dataset[\"CS.PA_PRED_TOMORROW\"] = pred_series\n",
        "\n",
        "# =========================\n",
        "# 5. RÉSULTAT FINAL\n",
        "# =========================\n",
        "\n",
        "# Création du signal d'achat / vente\n",
        "final_dataset[\"signal\"] = np.where(\n",
        "    final_dataset[\"CS.PA_PRED_TOMORROW\"] > 0.15,\n",
        "    \"buy\",\n",
        "    np.where(\n",
        "        final_dataset[\"CS.PA_PRED_TOMORROW\"] < -0.15,\n",
        "        \"sell\",\n",
        "        \"keep\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Vérification\n",
        "print(final_dataset[[\n",
        "    \"CS.PA\",\n",
        "    \"CS.PA_PRED_TOMORROW\",\n",
        "    \"signal\"\n",
        "]].tail(10))\n",
        "\n",
        "\n",
        "print(final_dataset.tail(10))\n",
        "\n",
        "# Sauvegarde\n",
        "final_dataset.to_csv(\n",
        "    \"CS_PREDICTION_DATASET.csv\"\n",
        ")"
      ],
      "metadata": {
        "id": "HqrQ5wv0WwYg"
      },
      "id": "HqrQ5wv0WwYg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# URW.PA prediction historique for validation"
      ],
      "metadata": {
        "id": "zyY4sc6rMDr0"
      },
      "id": "zyY4sc6rMDr0"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# =========================\n",
        "# 1. CHARGEMENT DU DATASET\n",
        "# =========================\n",
        "\n",
        "df = pd.read_csv(\n",
        "    \"DATASET_1000DAYS_VARIATION.csv\",\n",
        "    parse_dates=[\"date\"]\n",
        ").set_index(\"date\")\n",
        "\n",
        "# On ne garde que les colonnes utiles\n",
        "df = df[[\"GC=F\", \"^NDX\", \"AAPL\", \"URW.PA\"]].dropna()\n",
        "\n",
        "# =========================\n",
        "# 2. FEATURES & TARGET\n",
        "# =========================\n",
        "\n",
        "X = df[[\"GC=F\", \"^NDX\", \"AAPL\"]]\n",
        "y = df[\"URW.PA\"].shift(-1)  # URW.PA à J+1\n",
        "\n",
        "data = pd.concat([X, y], axis=1).dropna()\n",
        "data.columns = [\"GC=F\", \"^NDX\", \"AAPL\", \"CS_PRED_TARGET\"]\n",
        "\n",
        "# =========================\n",
        "# 3. WALK-FORWARD PREDICTION\n",
        "# =========================\n",
        "\n",
        "predictions = []\n",
        "\n",
        "MIN_TRAIN_SIZE = 60  # minimum historique pour entraîner\n",
        "\n",
        "for i in range(MIN_TRAIN_SIZE, len(data)):\n",
        "\n",
        "    train = data.iloc[:i]\n",
        "\n",
        "    X_train = sm.add_constant(train[[\"GC=F\", \"^NDX\", \"AAPL\"]])\n",
        "    y_train = train[\"CS_PRED_TARGET\"]\n",
        "\n",
        "    model = sm.OLS(y_train, X_train).fit()\n",
        "\n",
        "    X_today = pd.DataFrame(\n",
        "        [data.iloc[i][[\"GC=F\", \"^NDX\", \"AAPL\"]]],\n",
        "        columns=[\"GC=F\", \"^NDX\", \"AAPL\"]\n",
        "    )\n",
        "\n",
        "    X_today = sm.add_constant(X_today, has_constant=\"add\")\n",
        "\n",
        "    pred = model.predict(X_today).iloc[0]\n",
        "\n",
        "    predictions.append(pred)\n",
        "\n",
        "# =========================\n",
        "# 4. AJOUT DE LA COLONNE DE PRÉDICTION\n",
        "# =========================\n",
        "\n",
        "# Aligner avec les dates\n",
        "pred_series = pd.Series(\n",
        "    predictions,\n",
        "    index=data.index[MIN_TRAIN_SIZE:],\n",
        "    name=\"URW.PA_PRED_TOMORROW\"\n",
        ")\n",
        "\n",
        "final_dataset = df.copy()\n",
        "final_dataset[\"URW.PA_PRED_TOMORROW\"] = pred_series\n",
        "\n",
        "# =========================\n",
        "# 5. RÉSULTAT FINAL\n",
        "# =========================\n",
        "\n",
        "# Création du signal d'achat / vente\n",
        "final_dataset[\"signal\"] = np.where(\n",
        "    final_dataset[\"URW.PA_PRED_TOMORROW\"] > 0.15,\n",
        "    \"buy\",\n",
        "    np.where(\n",
        "        final_dataset[\"URW.PA_PRED_TOMORROW\"] < -0.15,\n",
        "        \"sell\",\n",
        "        \"keep\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Vérification\n",
        "print(final_dataset[[\n",
        "    \"URW.PA\",\n",
        "    \"URW.PA_PRED_TOMORROW\",\n",
        "    \"signal\"\n",
        "]].tail(10))\n",
        "\n",
        "\n",
        "print(final_dataset.tail(10))\n",
        "\n",
        "# Sauvegarde\n",
        "final_dataset.to_csv(\n",
        "    \"URW_PREDICTION_DATASET.csv\"\n",
        ")"
      ],
      "metadata": {
        "id": "khd_HR51LwOG"
      },
      "execution_count": null,
      "outputs": [],
      "id": "khd_HR51LwOG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect saxo bank"
      ],
      "metadata": {
        "id": "R_gn7zKPNkJh"
      },
      "id": "R_gn7zKPNkJh"
    },
    {
      "cell_type": "code",
      "source": [
        "# test conncetion Saxo bank simulation\n",
        "\n",
        "import requests\n",
        "import json\n",
        "\n",
        "# =========================\n",
        "# CONFIGURATION\n",
        "# =========================\n",
        "\n",
        "ACCESS_TOKEN = \"eyJhbGciOiJFUzI1NiIsIng1dCI6IjY3NEM0MjFEMzZEMUE1OUNFNjFBRTIzMjMyOTVFRTAyRTc3MDMzNTkifQ.eyJvYWEiOiI3Nzc3NSIsImlzcyI6Im9hIiwiYWlkIjoiMTA5IiwidWlkIjoiMWN1NWpOclFzanVKMkY2VXlLYTg5dz09IiwiY2lkIjoiMWN1NWpOclFzanVKMkY2VXlLYTg5dz09IiwiaXNhIjoiRmFsc2UiLCJ0aWQiOiIyMDAyIiwic2lkIjoiMzYwNGFlY2NmYTc3NGNlNmEzNGZmNDIyNGUyZDBmNWEiLCJkZ2kiOiI4NCIsImV4cCI6IjE3Njg4MTEzMjgiLCJvYWwiOiIxRiIsImlpZCI6IjFkNzAzNjg4NzM4MTQzNjMwNGE1MDhkZTRjNTUxOTUwIn0.NuSPihbRVQ_YHoWnW-sQHESQ9QNBExUgGpEM-GaD7gWOQfhr2OU7D4qmgGjhLEW7FNDKsdkL0bRfwf5xuOzftg\"\n",
        "BASE_URL = \"https://gateway.saxobank.com/sim/openapi\"  # ou /sim/openapi\n",
        "SYMBOL = {\"URW.PA\" : \"19099381\"}\n",
        "EXCHANGE = \"Euronext Paris\"\n",
        "\n",
        "HEADERS = {\n",
        "    \"Authorization\": f\"Bearer {ACCESS_TOKEN}\",\n",
        "    \"Accept\" : \"*/*\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "def get_AccountKeys():\n",
        "    url = f\"{BASE_URL}/port/v1/accounts/me\"\n",
        "    response = requests.get(url, headers=HEADERS)\n",
        "    response.raise_for_status()\n",
        "    return response.json()[\"Data\"]\n",
        "\n",
        "def get_Balances(AccountKey):\n",
        "    url = f\"{BASE_URL}/port/v1/balances?AccountKey=\"+AccountKey+\"&ClientKey=\"+AccountKey\n",
        "    response = requests.get(url, headers=HEADERS)\n",
        "    response.raise_for_status()\n",
        "    return response.json()\n",
        "\n",
        "def get_TickerPosition(Uic):\n",
        "    url = f\"{BASE_URL}/trade/v1/infoprices/list?AccountKey=\"+AccountKey+\"&Uics=\"+Uic+\"&AssetType=Stock&Amount=100000&FieldGroups=DisplayAndFormat,Quote\"\n",
        "    response = requests.get(url, headers=HEADERS)\n",
        "    response.raise_for_status()\n",
        "    return response.json()\n",
        "\n",
        "AccountKeys = get_AccountKeys()\n",
        "AccountKey = AccountKeys[0][\"AccountKey\"]\n",
        "Balances = get_Balances(AccountKey)\n",
        "URW = get_TickerPosition(SYMBOL[\"URW.PA\"])\n",
        "print(URW)\n",
        "\n",
        "print(AccountKey)\n",
        "print(Balances)"
      ],
      "metadata": {
        "id": "SWGNJbYASMC1"
      },
      "id": "SWGNJbYASMC1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Today prediction"
      ],
      "metadata": {
        "id": "HDaUtak-Lj_h"
      },
      "id": "HDaUtak-Lj_h"
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CS.PA – SIGNAL QUANT +\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "import json\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from datetime import datetime\n",
        "\n",
        "# =========================\n",
        "# PARAMÈTRES GÉNÉRAUX\n",
        "# =========================\n",
        "\n",
        "CSV_PATH = \"DATASET_1000DAYS_VARIATION.csv\"\n",
        "\n",
        "FEATURES = [\"^NDX\", \"LIN\",\"ABBV\"]\n",
        "TARGET   = \"CS.PA\"\n",
        "\n",
        "BUY_THRESHOLD  = 0.5\n",
        "SELL_THRESHOLD = -0.5\n",
        "\n",
        "MIN_TRAIN_SIZE = 60\n",
        "\n",
        "# =========================\n",
        "# 1. CHARGER DATASET HISTORIQUE\n",
        "# =========================\n",
        "\n",
        "df = pd.read_csv(\n",
        "    CSV_PATH,\n",
        "    parse_dates=[\"date\"]\n",
        ").set_index(\"date\")\n",
        "\n",
        "df = df[FEATURES + [TARGET]].dropna()\n",
        "\n",
        "# =========================\n",
        "# 2. ENTRAÎNEMENT DU MODÈLE (lag = 1)\n",
        "# =========================\n",
        "\n",
        "X = df[FEATURES]\n",
        "y = df[TARGET].shift(-1)\n",
        "\n",
        "data = pd.concat([X, y], axis=1).dropna()\n",
        "data.columns = FEATURES + [\"CS_TARGET\"]\n",
        "\n",
        "X_train = sm.add_constant(data[FEATURES], has_constant=\"add\")\n",
        "y_train = data[\"CS_TARGET\"]\n",
        "\n",
        "model = sm.OLS(y_train, X_train).fit()\n",
        "\n",
        "# =========================\n",
        "# 3. DONNÉES LIVE (clôture US)\n",
        "# =========================\n",
        "\n",
        "tickers = FEATURES + [TARGET]\n",
        "\n",
        "prices = yf.download(\n",
        "    tickers,\n",
        "    period=\"2d\",\n",
        "    interval=\"1d\",\n",
        "    auto_adjust=True,\n",
        "    progress=False\n",
        ")[\"Close\"]\n",
        "\n",
        "returns_today = prices.pct_change(fill_method=None).iloc[-1] * 100\n",
        "\n",
        "missing = returns_today[FEATURES].isna()\n",
        "\n",
        "if missing.any():\n",
        "    print(\"⚠️ Marchés non clôturés :\", missing[missing].index.tolist())\n",
        "    predicted_return = 0.0\n",
        "    signal = \"KEEP\"\n",
        "\n",
        "else:\n",
        "    X_today = pd.DataFrame(\n",
        "        [[\n",
        "            returns_today[\"^NDX\"],\n",
        "            returns_today[\"LIN\"],\n",
        "            returns_today[\"ABBV\"]\n",
        "        ]],\n",
        "        columns=FEATURES\n",
        "    )\n",
        "\n",
        "    X_today = sm.add_constant(X_today, has_constant=\"add\")\n",
        "\n",
        "    predicted_return = model.predict(X_today).iloc[0]\n",
        "\n",
        "    if predicted_return > BUY_THRESHOLD:\n",
        "        signal = \"BUY\"\n",
        "    elif predicted_return < SELL_THRESHOLD:\n",
        "        signal = \"SELL\"\n",
        "    else:\n",
        "        signal = \"KEEP\"\n",
        "\n",
        "# =========================\n",
        "# 6. SORTIE\n",
        "# =========================\n",
        "\n",
        "print(\"\\n==============================\")\n",
        "print(\"   SIGNAL URW.PA (J+1)\")\n",
        "print(\"==============================\")\n",
        "print(\"Date :\", datetime.now().strftime(\"%Y-%m-%d %H:%M CET\"))\n",
        "print(\"\\nVariations aujourd'hui (%)\")\n",
        "print(returns_today[FEATURES])\n",
        "print(f\"\\nPrévision URW.PA J+1 : {predicted_return:.3f} %\")\n",
        "print(\"==============================\\n\")"
      ],
      "metadata": {
        "id": "9RikQhCXSRQb"
      },
      "execution_count": null,
      "outputs": [],
      "id": "9RikQhCXSRQb"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}