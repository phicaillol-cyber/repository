{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phicaillol-cyber/repository/blob/main/predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset creation"
      ],
      "metadata": {
        "id": "c-sdParCMe8G"
      },
      "id": "c-sdParCMe8G"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a59ae70c-0532-4cf6-ac10-38d606068a6e",
      "metadata": {
        "id": "a59ae70c-0532-4cf6-ac10-38d606068a6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d24015e-3916-4e1e-cb55-a1056901331c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  131 of 131 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (710, 132)\n",
            "Ticker       date      AAPL      ABBV       ABT    ACA.PA       ACN      ADBE  \\\n",
            "0      2023-04-26 -0.006091 -1.879922 -1.109395  0.980396  0.188361 -1.766822   \n",
            "1      2023-04-27  2.839524 -7.991359  0.689649  1.263954  1.563398  2.302654   \n",
            "2      2023-04-28  0.754094  1.511395  0.885846  0.253248  1.757113  1.653111   \n",
            "3      2023-05-01 -0.053028  1.713873  0.579341       NaN -0.310401 -0.903169   \n",
            "4      2023-05-02 -0.619144 -1.359721  0.351008       NaN -0.959125 -1.467323   \n",
            "\n",
            "Ticker       ADI     AI.PA    AIR.PA  ...      ^DJI      ^FVX      ^IRX  \\\n",
            "0      -0.264988 -1.531105 -1.445588  ... -0.682825  1.104012  0.646074   \n",
            "1      -1.682707  0.995147  1.176655  ...  1.574353  3.505747  0.300900   \n",
            "2       1.272382  0.492676  1.274492  ...  0.804111 -1.832315 -1.540003   \n",
            "3       1.478732       NaN       NaN  ... -0.136256  2.743209 -1.178145   \n",
            "4       0.613596       NaN       NaN  ... -1.078266 -4.596747  3.597126   \n",
            "\n",
            "Ticker      ^NDX  ^SP500-15  ^SP500-20  ^STOXX50E      ^TNX      ^TYX  \\\n",
            "0       0.639445  -1.178632  -1.869386  -0.688469  1.060071  1.040807   \n",
            "1       2.760710   1.358454   1.985282   0.237823  2.797209  1.816214   \n",
            "2       0.653190   1.128840   0.923219   0.028918 -2.154201 -2.076679   \n",
            "3      -0.109622  -0.037471   0.550760        NaN  3.534183  3.806419   \n",
            "4      -0.890374  -0.948961  -1.048467        NaN -3.777280 -2.226297   \n",
            "\n",
            "Ticker       ^VIX  \n",
            "0        0.426439  \n",
            "1       -9.607216  \n",
            "2       -7.339994  \n",
            "3        1.901142  \n",
            "4       10.572144  \n",
            "\n",
            "[5 rows x 132 columns]\n",
            "Ticker       date      AAPL      ABBV       ABT    ACA.PA       ACN      ADBE  \\\n",
            "705    2026-01-13  0.307392  0.322674 -0.272786  0.708617 -1.480639 -5.408210   \n",
            "706    2026-01-14 -0.417543  0.516416  0.563154 -0.534756  4.241337 -1.771365   \n",
            "707    2026-01-15 -0.673181 -2.316460 -0.675407 -0.226378 -0.266868 -0.114967   \n",
            "708    2026-01-16 -1.037912 -0.311598 -1.432848 -0.453772 -0.542099 -2.620935   \n",
            "709    2026-01-19       NaN       NaN       NaN       NaN       NaN       NaN   \n",
            "\n",
            "Ticker       ADI     AI.PA    AIR.PA  ...      ^DJI      ^FVX      ^IRX  \\\n",
            "705     0.799703 -0.541494  1.873700  ... -0.803003 -0.637110  0.764222   \n",
            "706     0.600925  2.279052 -2.157130  ... -0.086110 -0.694631  0.000000   \n",
            "707     1.379246 -0.507546 -0.278483  ...  0.595757  1.210656  0.140453   \n",
            "708    -0.612382 -0.945629  1.186869  ... -0.168101  1.754386 -0.224408   \n",
            "709          NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
            "\n",
            "Ticker      ^NDX  ^SP500-15  ^SP500-20  ^STOXX50E      ^TNX      ^TYX  \\\n",
            "705    -0.177259   0.292286   0.513865   0.224894 -0.382130 -0.247936   \n",
            "706    -1.072218  -0.176485   0.139687  -0.410961 -0.743230 -0.683513   \n",
            "707     0.318586   0.330885   0.929738   0.601000  0.483091 -0.166838   \n",
            "708    -0.069717  -0.441340   0.647595  -0.193506  1.706733  1.107165   \n",
            "709          NaN        NaN        NaN        NaN       NaN       NaN   \n",
            "\n",
            "Ticker      ^VIX  \n",
            "705     5.687828  \n",
            "706     4.818526  \n",
            "707    -5.432835  \n",
            "708     0.126259  \n",
            "709          NaN  \n",
            "\n",
            "[5 rows x 132 columns]\n",
            "NaN par colonne :\n",
            "Ticker\n",
            "^CIISCSEP    710\n",
            "FISV          51\n",
            "AAPL          49\n",
            "ABT           49\n",
            "ABBV          49\n",
            "ADI           49\n",
            "ACN           49\n",
            "ASML          49\n",
            "AMZN          49\n",
            "AMGN          49\n",
            "ADBE          49\n",
            "AVGO          49\n",
            "BAC           49\n",
            "BKNG          49\n",
            "CSCO          49\n",
            "dtype: int64\n",
            "Creation de CAC40_TICKERS.csv et du dataset DATASET_1000DAYS_VARIATION.csv terminée: \n",
            "2026-01-19 07:56:51.551198\n"
          ]
        }
      ],
      "source": [
        "### Creation du dataset de variation des tickers des 1000 derniers jours\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Définir la période de 1000 jours\n",
        "end_date = datetime.now()\n",
        "start_date = end_date - timedelta(days=1000)\n",
        "\n",
        "# Liste des tickers du CAC 40 (exemple : 'OR.PA' pour L'Oréal)\n",
        "cac40_tickers = cac40_tickers = [\n",
        "    \"AI.PA\",   # Air Liquide\n",
        "    \"AIR.PA\",  # Airbus\n",
        "    \"ALO.PA\",  # Alstom\n",
        "    \"CS.PA\",   # AXA\n",
        "    \"BNP.PA\",  # BNP Paribas\n",
        "    \"EN.PA\",   # Bouygues\n",
        "    \"CAP.PA\",  # Capgemini\n",
        "    \"CA.PA\",   # Carrefour\n",
        "    \"ACA.PA\",  # Crédit Agricole\n",
        "    \"BN.PA\",   # Danone\n",
        "    \"DSY.PA\",  # Dassault Systèmes\n",
        "    \"EDEN.PA\", # Edenred\n",
        "    \"ENGI.PA\", # Engie\n",
        "    \"EL.PA\",   # EssilorLuxottica\n",
        "    \"ERF.PA\",  # Eurofins Scientific\n",
        "    \"RMS.PA\",  # Hermès\n",
        "    \"KER.PA\",  # Kering\n",
        "    \"LR.PA\",   # Legrand\n",
        "    \"OR.PA\",   # L'Oréal\n",
        "    \"MC.PA\",   # LVMH\n",
        "    \"ML.PA\",   # Michelin\n",
        "    \"ORA.PA\",  # Orange\n",
        "    \"RI.PA\",   # Pernod Ricard\n",
        "    \"PUB.PA\",  # Publicis\n",
        "    \"RNO.PA\",  # Renault\n",
        "    \"SAF.PA\",  # Safran\n",
        "    \"SGO.PA\",  # Saint-Gobain\n",
        "    \"SAN.PA\",  # Sanofi\n",
        "    \"SU.PA\",   # Schneider Electric\n",
        "    \"GLE.PA\",  # Société Générale\n",
        "    \"TEP.PA\",  # Teleperformance\n",
        "    \"HO.PA\",   # Thales\n",
        "    \"TTE.PA\",  # TotalEnergies\n",
        "    \"URW.PA\",  # Unibail-Rodamco-Westfield\n",
        "    \"VIE.PA\",  # Veolia\n",
        "    \"DG.PA\",   # Vinci\n",
        "    \"VIV.PA\",  # Vivendi\n",
        "    \"WLN.PA\"   # Worldline\n",
        "]\n",
        "\n",
        "# Liste des tickers du NASDAQ (exemple : 'AAPL' pour Apple)\n",
        "nasdaq_tickers = nasdaq_top_40 = [\n",
        "    \"AAPL\",  # Apple\n",
        "    \"MSFT\",  # Microsoft\n",
        "    \"GOOGL\", # Alphabet (Google)\n",
        "    \"AMZN\",  # Amazon\n",
        "    \"META\",  # Meta (Facebook)\n",
        "    \"NVDA\",  # NVIDIA\n",
        "    \"TSLA\",  # Tesla\n",
        "    \"AVGO\",  # Broadcom\n",
        "    \"PEP\",   # PepsiCo\n",
        "    \"COST\",  # Costco\n",
        "    \"ADBE\",  # Adobe\n",
        "    \"NFLX\",  # Netflix\n",
        "    \"PYPL\",  # PayPal\n",
        "    \"INTC\",  # Intel\n",
        "    \"CSCO\",  # Cisco\n",
        "    \"CMCSA\", # Comcast\n",
        "    \"AMGN\",  # Amgen\n",
        "    \"TXN\",   # Texas Instruments\n",
        "    \"QCOM\",  # Qualcomm\n",
        "    \"HON\",   # Honeywell\n",
        "    \"AMD\",   # Advanced Micro Devices (AMD)\n",
        "    \"ISRG\",  # Intuitive Surgical\n",
        "    \"SBUX\",  # Starbucks\n",
        "    \"MDLZ\",  # Mondelēz\n",
        "    \"AMAT\",  # Applied Materials\n",
        "    \"LRCX\",  # Lam Research\n",
        "    \"ADI\",   # Analog Devices\n",
        "    \"MU\",    # Micron Technology\n",
        "    \"ASML\", # ASML Holding\n",
        "    \"MRNA\", # Moderna\n",
        "    \"ILMN\",  # Illumina\n",
        "    \"BKNG\",  # Booking Holdings\n",
        "    \"REGN\",  # Regeneron\n",
        "    \"KDP\",   # Keurig Dr Pepper\n",
        "    \"MNST\",  # Monster Beverage\n",
        "    \"FISV\",  # Fiserv\n",
        "    \"WDAY\",  # Workday\n",
        "    \"TEAM\"   # Atlassian\n",
        "]\n",
        "\n",
        "nyse_tickers = nyse_top_40 = [\n",
        "    \"XOM\",   # Exxon Mobil\n",
        "    \"JNJ\",   # Johnson & Johnson\n",
        "    \"V\",     # Visa\n",
        "    \"PG\",    # Procter & Gamble\n",
        "    \"MA\",    # Mastercard\n",
        "    \"HD\",    # Home Depot\n",
        "    \"DIS\",   # Disney\n",
        "    \"VZ\",    # Verizon\n",
        "    \"MCD\",   # McDonald's\n",
        "    \"CVX\",   # Chevron\n",
        "    \"WMT\",   # Walmart\n",
        "    \"BAC\",   # Bank of America\n",
        "    \"PFE\",   # Pfizer\n",
        "    \"KO\",    # Coca-Cola\n",
        "    \"MRK\",   # Merck\n",
        "    \"ABBV\",  # AbbVie\n",
        "    \"CRM\",   # Salesforce\n",
        "    \"ABT\",   # Abbott Laboratories\n",
        "    \"PEP\",   # PepsiCo\n",
        "    \"C\",     # Citigroup\n",
        "    \"TMO\",   # Thermo Fisher Scientific\n",
        "    \"LIN\",   # Linde\n",
        "    \"CSCO\",  # Cisco (aussi coté sur NYSE)\n",
        "    \"ACN\",   # Accenture\n",
        "    \"CVS\",   # CVS Health\n",
        "    \"ORCL\",  # Oracle\n",
        "    \"NKE\",   # Nike\n",
        "    \"LLY\",   # Eli Lilly\n",
        "    \"DHR\",   # Danaher\n",
        "    \"UNH\",   # UnitedHealth\n",
        "    \"PM\",    # Philip Morris\n",
        "    \"IBM\",   # IBM\n",
        "    \"MMM\",   # 3M\n",
        "    \"MDT\",   # Medtronic\n",
        "    \"GE\",    # General Electric\n",
        "    \"GS\",    # Goldman Sachs\n",
        "    \"CAT\",   # Caterpillar\n",
        "    \"RTX\",   # Raytheon Technologies\n",
        "    \"UPS\",   # UPS\n",
        "    \"MO\",    # Altria\n",
        "]\n",
        "\n",
        "# Inclure également les indices macro (VIX, Dollar Index, Brent, Or)\n",
        "macro_tickers = [\n",
        "    \"GC=F\",        # Or (Gold Futures COMEX)\n",
        "    \"BZ=F\",        # Pétrole Brent (Brent Crude Oil Futures)\n",
        "    \"^NDX\",        # NASDAQ 100 (technologie US, croissance)\n",
        "    \"^DJI\",        # Dow Jones Industrial Average (blue chips US)\n",
        "    \"^SP500-20\",   # S&P 500 Industrials (secteur industriel)\n",
        "    \"^SP500-15\",   # S&P 500 Materials (matières premières)\n",
        "    \"^STOXX50E\",   # Euro STOXX 50 (grandes capitalisations zone euro)\n",
        "    \"DX-Y.NYB\",    # Dollar Index (DXY – force du dollar US)\n",
        "    \"EUR=X\",       # Taux de change EUR/USD\n",
        "    \"CHF=X\",       # Taux de change USD/CHF (valeur refuge)\n",
        "    \"^VIX\",        # Indice de volatilité (peur / stress de marché)\n",
        "    \"^IRX\",        # Taux US 13 semaines (T-Bills court terme)\n",
        "    \"^FVX\",        # Taux US 5 ans\n",
        "    \"^TNX\",        # Taux US 10 ans (benchmark macro mondial)\n",
        "    \"^TYX\",        # Taux US 30 ans (long terme)\n",
        "    \"^CIISCSEP\",   # Indice de surprises économiques Citi (US)\n",
        "    \"CDX\"          # Indice de crédit (Credit Default Swaps – stress crédit)\n",
        "]\n",
        "\n",
        "\n",
        "# Combiner toutes les listes de tickers\n",
        "all_tickers = cac40_tickers + nasdaq_tickers + nyse_tickers + macro_tickers\n",
        "\n",
        "# Télécharger les données boursières\n",
        "data = yf.download(all_tickers, start=start_date, end=end_date,auto_adjust=True)\n",
        "\n",
        "# Calculer la variation en pourcentage par rapport à la clôture précédente\n",
        "variation = data[\"Close\"].pct_change(fill_method=None) * 100\n",
        "variation = variation.dropna(how=\"all\")\n",
        "\n",
        "variation.index = pd.to_datetime(variation.index)\n",
        "variation.index.name = \"date\"\n",
        "\n",
        "dataset_ts = variation.reset_index()\n",
        "dataset_ts = dataset_ts.sort_values(\"date\")\n",
        "\n",
        "print(\"Shape:\", dataset_ts.shape)\n",
        "print(dataset_ts.head())\n",
        "print(dataset_ts.tail())\n",
        "print(\"NaN par colonne :\")\n",
        "print(variation.isna().sum().sort_values(ascending=False).head(15))\n",
        "\n",
        "pd.DataFrame(cac40_tickers, columns=[\"Ticker\"]).to_csv(\"CAC40_TICKERS.csv\", index=False)\n",
        "dataset_ts.to_csv(\"DATASET_1000DAYS_VARIATION.csv\", index=False)\n",
        "\n",
        "now = datetime.now()\n",
        "print(\"Creation de CAC40_TICKERS.csv et du dataset DATASET_1000DAYS_VARIATION.csv terminée: \")\n",
        "print(now)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lead Lag search"
      ],
      "metadata": {
        "id": "Z1jerT1XM-pP"
      },
      "id": "Z1jerT1XM-pP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d90c73b-74f4-4a70-8588-6a07e48a09a7",
      "metadata": {
        "id": "9d90c73b-74f4-4a70-8588-6a07e48a09a7"
      },
      "outputs": [],
      "source": [
        "### Recherche des leads/lags sur les actions du CAC40\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Charger le CSV\n",
        "dataset_ts = pd.read_csv(\n",
        "    \"DATASET_1000DAYS_VARIATION.csv\",\n",
        "    parse_dates=[\"date\"]   # très important\n",
        ")\n",
        "\n",
        "# Trier par date (sécurité)\n",
        "dataset_ts = dataset_ts.sort_values(\"date\")\n",
        "\n",
        "# Optionnel : remettre la date en index\n",
        "dataset_ts = dataset_ts.set_index(\"date\")\n",
        "\n",
        "def scan_lead_lag_cac40(\n",
        "    df,\n",
        "    cac40_cols,\n",
        "    other_cols,\n",
        "    max_lag=20,\n",
        "    min_obs=40,\n",
        "    method=\"pearson\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Scan exhaustif lead/lag entre :\n",
        "    - other_cols (X candidates)\n",
        "    - cac40_cols (Y targets)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "    \"\"\"\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for y in cac40_cols:\n",
        "        for x in other_cols:\n",
        "\n",
        "            if x == y:\n",
        "                continue\n",
        "\n",
        "            best_row = None\n",
        "\n",
        "            for lag in range(-max_lag, max_lag + 1):\n",
        "\n",
        "                if lag < 0:\n",
        "                    x_shifted = df[x].shift(-lag)\n",
        "                    y_shifted = df[y]\n",
        "                else:\n",
        "                    x_shifted = df[x]\n",
        "                    y_shifted = df[y].shift(lag)\n",
        "\n",
        "                pair = pd.concat([x_shifted, y_shifted], axis=1).dropna()\n",
        "\n",
        "                if len(pair) < min_obs:\n",
        "                    continue\n",
        "\n",
        "                corr = pair.iloc[:, 0].corr(pair.iloc[:, 1], method=method)\n",
        "\n",
        "                if pd.isna(corr):\n",
        "                    continue\n",
        "\n",
        "                row = {\n",
        "                    \"x\": x,\n",
        "                    \"y\": y,\n",
        "                    \"lag\": lag,\n",
        "                    \"correlation\": corr,\n",
        "                    \"abs_corr\": abs(corr),\n",
        "                    \"direction\": \"inverse\" if corr < 0 else \"same\",\n",
        "                    \"n_obs\": len(pair)\n",
        "                }\n",
        "\n",
        "                if best_row is None or row[\"abs_corr\"] > best_row[\"abs_corr\"]:\n",
        "                    best_row = row\n",
        "\n",
        "            if best_row is not None:\n",
        "                results.append(best_row)\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "df = dataset_ts\n",
        "cac40_cols = pd.read_csv(\"CAC40_TICKERS.csv\")['Ticker'].tolist()\n",
        "other_cols = [c for c in df.columns if c not in cac40_cols]\n",
        "\n",
        "results = scan_lead_lag_cac40(\n",
        "    df=df,\n",
        "    cac40_cols=cac40_cols,\n",
        "    other_cols=other_cols,\n",
        "    max_lag=20,\n",
        "    min_obs=40\n",
        ")\n",
        "\n",
        "results.sort_values(\"abs_corr\", ascending=False).head(20)\n",
        "results[\n",
        "    results[\"direction\"] == \"inverse\"\n",
        "].sort_values(\"abs_corr\", ascending=False).head(20)\n",
        "\n",
        "results[results[\"y\"] == \"MC.PA\"] \\\n",
        "    .sort_values(\"abs_corr\", ascending=False) \\\n",
        "    .head(10)\n",
        "\n",
        "print(\"Shape:\", results.shape)\n",
        "results.to_csv(\"LEAD_LAG_SCAN_CAC40.csv\", index=False)\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "now = datetime.now()\n",
        "print(\"Recherche des leads/lags sur les actions du CAC40 terminée: \")\n",
        "print(now)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Candidates selection"
      ],
      "metadata": {
        "id": "5rIc4-G4NG_T"
      },
      "id": "5rIc4-G4NG_T"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3b366ed8-1943-496d-a0dd-31c35f4ee81a"
      },
      "outputs": [],
      "source": [
        "### Recherche des variables candidates qui ont des leads/lags significatifs sur le CAC40\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# =========================\n",
        "# 1. CHARGEMENT DU CSV\n",
        "# =========================\n",
        "\n",
        "leadlag = pd.read_csv(\"LEAD_LAG_SCAN_CAC40.csv\")\n",
        "\n",
        "print(\"Dataset initial :\", leadlag.shape)\n",
        "\n",
        "# =========================\n",
        "# 2. FILTRE : LAG ≠ 0\n",
        "# =========================\n",
        "\n",
        "leadlag = leadlag[leadlag[\"lag\"] != 0]\n",
        "\n",
        "print(\"Après suppression lag = 0 :\", leadlag.shape)\n",
        "\n",
        "# =========================\n",
        "# 3. CLASSIFICATION DU RISQUE\n",
        "# =========================\n",
        "\n",
        "def classify_risk(abs_corr, n_obs):\n",
        "    if abs_corr >= 0.55 and n_obs >= 80:\n",
        "        return \"very_low_risk\"\n",
        "    elif abs_corr >= 0.45 and n_obs >= 60:\n",
        "        return \"low_risk\"\n",
        "    elif abs_corr >= 0.40 and n_obs >= 50:\n",
        "        return \"medium_risk\"\n",
        "    elif abs_corr >= 0.30 and n_obs >= 40:\n",
        "        return \"high_risk\"\n",
        "    else:\n",
        "        return \"very_high_risk\"\n",
        "\n",
        "leadlag[\"risk_level\"] = leadlag.apply(\n",
        "    lambda r: classify_risk(r[\"abs_corr\"], r[\"n_obs\"]),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# 4. TRI FINAL (DU + SÛR AU + RISQUÉ)\n",
        "# =========================\n",
        "\n",
        "risk_order = [\n",
        "    \"very_low_risk\",\n",
        "    \"low_risk\",\n",
        "    \"medium_risk\",\n",
        "    \"high_risk\",\n",
        "    \"very_high_risk\"\n",
        "]\n",
        "\n",
        "leadlag[\"risk_level\"] = pd.Categorical(\n",
        "    leadlag[\"risk_level\"],\n",
        "    categories=risk_order,\n",
        "    ordered=True\n",
        ")\n",
        "\n",
        "leadlag_sorted = leadlag.sort_values(\n",
        "    [\"risk_level\", \"abs_corr\"],\n",
        "    ascending=[True, False]\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# 5. CONTRÔLE RAPIDE\n",
        "# =========================\n",
        "\n",
        "print(\"\\nTop 20 relations les plus sûres (lag ≠ 0) :\")\n",
        "print(leadlag_sorted.head(20))\n",
        "\n",
        "# =========================\n",
        "# 6. SAUVEGARDE\n",
        "# =========================\n",
        "\n",
        "leadlag_sorted.to_csv(\n",
        "    \"LEAD_LAG_SCAN_CAC40_CLASSIFIED_LAG_NOT_ZERO.csv\",\n",
        "    index=False\n",
        ")\n",
        "\n",
        "print(\"\\nCSV sauvegardé : LEAD_LAG_SCAN_CAC40_CLASSIFIED_LAG_NOT_ZERO.csv\")\n",
        "\n",
        "# Charger le scan lead/lag\n",
        "leadlag = pd.read_csv(\"LEAD_LAG_SCAN_CAC40.csv\")\n",
        "\n",
        "# Filtre SAFE\n",
        "filtered = leadlag[\n",
        "    (leadlag[\"lag\"] != 0) &\n",
        "    (leadlag[\"abs_corr\"] >= 0.25) &\n",
        "    (leadlag[\"n_obs\"] >= 40)\n",
        "]\n",
        "\n",
        "# Extraire les candidats (variables X)\n",
        "candidatesX = (\n",
        "    filtered[\"x\"]\n",
        "    .value_counts()\n",
        "    .reset_index()\n",
        ")\n",
        "candidatesX.columns = [\"variable\", \"count\"]\n",
        "print(\"\\nCandidate variables\")\n",
        "print(candidatesX)\n",
        "pd.DataFrame(candidatesX, columns=[\"variable\"]).to_csv(\"CANDIDATES_VARIABLES.csv\", index=False)\n",
        "\n",
        "# Extraire les cibles (variables y)\n",
        "candidatesY = (\n",
        "    filtered[\"y\"]\n",
        "    .value_counts()\n",
        "    .reset_index()\n",
        ")\n",
        "candidatesY.columns = [\"variable\", \"count\"]\n",
        "print(\"\\nCandidate taget\")\n",
        "print(candidatesY)\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "now = datetime.now()\n",
        "print(\"Recherche des variables candidates CANDIDATES_VARIABLES.csv terminée: \")\n",
        "print(now)\n",
        "\n",
        "\n"
      ],
      "id": "3b366ed8-1943-496d-a0dd-31c35f4ee81a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Search best 2-3 variables combination"
      ],
      "metadata": {
        "id": "8LbcTNGrNYUz"
      },
      "id": "8LbcTNGrNYUz"
    },
    {
      "cell_type": "code",
      "source": [
        "### Meilleures correlations avec une combinaison de 3 variables max avec laf de 1 à 20 jours\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from itertools import combinations\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "# Charger le CSV\n",
        "dataset_ts = pd.read_csv(\n",
        "    \"DATASET_1000DAYS_VARIATION.csv\",\n",
        "    parse_dates=[\"date\"]   # très important\n",
        ")\n",
        "\n",
        "# Trier par date (sécurité)\n",
        "dataset_ts = dataset_ts.sort_values(\"date\")\n",
        "\n",
        "# Optionnel : remettre la date en index\n",
        "dataset_ts = dataset_ts.set_index(\"date\")\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "def composite_factor(df, cols):\n",
        "    X = df[list(cols)]\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = pd.DataFrame(\n",
        "        scaler.fit_transform(X),\n",
        "        index=X.index,\n",
        "        columns=cols\n",
        "    )\n",
        "    return X_scaled.mean(axis=1)\n",
        "\n",
        "def lead_corr(df, factor, target, lag, min_obs=60):\n",
        "    y = df[target].shift(-lag)\n",
        "    data = pd.concat([factor, y], axis=1).dropna()\n",
        "\n",
        "    if len(data) < min_obs:\n",
        "        return None\n",
        "\n",
        "    return data.iloc[:, 0].corr(data.iloc[:, 1])\n",
        "\n",
        "\n",
        "df = dataset_ts\n",
        "\n",
        "# Charger les candidats CSV\n",
        "#candidate_vars = pd.read_csv(\"CANDIDATES_VARIABLES.csv\")['variable'].tolist()\n",
        "candidate_vars = [\"^VIX\",\"^TNX\",\"GC=F\",\"BZ=F\",\"DX-Y.NYB\",\"^NDX\",\"AAPL\",\"^STOXX50E\",\"LIN\",\"ABBV\"]\n",
        "cac40_cols = pd.read_csv(\"CAC40_TICKERS.csv\")['Ticker'].tolist()\n",
        "\n",
        "from itertools import combinations\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def scan_all_cac40(\n",
        "    df,\n",
        "    cac40_cols,\n",
        "    candidate_vars,\n",
        "    lags=range(1, 20),\n",
        "    max_vars=3,\n",
        "    min_abs_corr=0.25,\n",
        "    min_obs=50\n",
        "):\n",
        "    results = []\n",
        "\n",
        "    for target in cac40_cols:\n",
        "\n",
        "        if target not in df.columns:\n",
        "            continue\n",
        "\n",
        "        for k in range(2, max_vars + 1):\n",
        "            for combo in combinations(candidate_vars, k):\n",
        "\n",
        "                try:\n",
        "                    factor = composite_factor(df, combo)\n",
        "                except Exception:\n",
        "                    continue\n",
        "\n",
        "                for lag in lags:\n",
        "                    corr = lead_corr(df, factor, target, lag, min_obs=min_obs)\n",
        "\n",
        "                    if corr is None or np.isnan(corr):\n",
        "                        continue\n",
        "\n",
        "                    abs_corr = abs(corr)\n",
        "\n",
        "                    if abs_corr < min_abs_corr:\n",
        "                        continue\n",
        "\n",
        "                    results.append({\n",
        "                        \"target\": target,\n",
        "                        \"variables\": combo,\n",
        "                        \"n_vars\": k,\n",
        "                        \"lag\": lag,\n",
        "                        \"correlation\": corr,\n",
        "                        \"abs_corr\": abs_corr,\n",
        "                        \"n_obs\": len(\n",
        "                            pd.concat(\n",
        "                                [factor, df[target].shift(-lag)],\n",
        "                                axis=1\n",
        "                            ).dropna()\n",
        "                        )\n",
        "                    })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "results_cac40 = scan_all_cac40(\n",
        "    df=dataset_ts,\n",
        "    cac40_cols=cac40_cols,\n",
        "    candidate_vars=candidate_vars,\n",
        "    lags=range(1, 20),\n",
        "    max_vars=3,\n",
        "    min_abs_corr=0.25\n",
        ")\n",
        "\n",
        "print(\"Shape :\", results_cac40.shape)\n",
        "print(\"Colonnes :\", results_cac40.columns)\n",
        "\n",
        "# Check if results_cac40 is empty before attempting to sort\n",
        "if not results_cac40.empty:\n",
        "    print(results_cac40.sort_values(\"abs_corr\", ascending=False).head(20))\n",
        "else:\n",
        "    print(\"No significant correlations found based on the given criteria.\")\n",
        "\n",
        "results_cac40.to_csv(\"BEST_PROBA.csv\", index=False)\n",
        "\n",
        "now = datetime.now()\n",
        "print(\"Résultat des meilleures probabilités BEST_PROBA.csv terminé: \")\n",
        "print(now)\n"
      ],
      "metadata": {
        "id": "W2w5klVCX8ct"
      },
      "id": "W2w5klVCX8ct",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# URW.PA"
      ],
      "metadata": {
        "id": "Uij5aRPaK47h"
      },
      "id": "Uij5aRPaK47h"
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# URW.PA – SIGNAL QUANT + SAXO BANK EXECUTION\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "import json\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from datetime import datetime\n",
        "\n",
        "# =========================\n",
        "# PARAMÈTRES GÉNÉRAUX\n",
        "# =========================\n",
        "\n",
        "CSV_PATH = \"DATASET_1000DAYS_VARIATION.csv\"\n",
        "\n",
        "FEATURES = [\"GC=F\", \"^NDX\", \"AAPL\"]\n",
        "TARGET   = \"URW.PA\"\n",
        "\n",
        "BUY_THRESHOLD  = 0.5\n",
        "SELL_THRESHOLD = -0.5\n",
        "\n",
        "MIN_TRAIN_SIZE = 60\n",
        "\n",
        "# =========================\n",
        "# 1. CHARGER DATASET HISTORIQUE\n",
        "# =========================\n",
        "\n",
        "df = pd.read_csv(\n",
        "    CSV_PATH,\n",
        "    parse_dates=[\"date\"]\n",
        ").set_index(\"date\")\n",
        "\n",
        "df = df[FEATURES + [TARGET]].dropna()\n",
        "\n",
        "# =========================\n",
        "# 2. ENTRAÎNEMENT DU MODÈLE (lag = 1)\n",
        "# =========================\n",
        "\n",
        "X = df[FEATURES]\n",
        "y = df[TARGET].shift(-1)\n",
        "\n",
        "data = pd.concat([X, y], axis=1).dropna()\n",
        "data.columns = FEATURES + [\"URW_TARGET\"]\n",
        "\n",
        "X_train = sm.add_constant(data[FEATURES], has_constant=\"add\")\n",
        "y_train = data[\"URW_TARGET\"]\n",
        "\n",
        "model = sm.OLS(y_train, X_train).fit()\n",
        "\n",
        "# =========================\n",
        "# 3. DONNÉES LIVE (clôture US)\n",
        "# =========================\n",
        "\n",
        "tickers = FEATURES + [TARGET]\n",
        "\n",
        "prices = yf.download(\n",
        "    tickers,\n",
        "    period=\"2d\",\n",
        "    interval=\"1d\",\n",
        "    auto_adjust=True,\n",
        "    progress=False\n",
        ")[\"Close\"]\n",
        "\n",
        "returns_today = prices.pct_change(fill_method=None).iloc[-1] * 100\n",
        "\n",
        "missing = returns_today[FEATURES].isna()\n",
        "\n",
        "if missing.any():\n",
        "    print(\"⚠️ Marchés non clôturés :\", missing[missing].index.tolist())\n",
        "    predicted_return = 0.0\n",
        "    signal = \"KEEP\"\n",
        "\n",
        "else:\n",
        "    X_today = pd.DataFrame(\n",
        "        [[\n",
        "            returns_today[\"GC=F\"],\n",
        "            returns_today[\"^NDX\"],\n",
        "            returns_today[\"AAPL\"]\n",
        "        ]],\n",
        "        columns=FEATURES\n",
        "    )\n",
        "\n",
        "    X_today = sm.add_constant(X_today, has_constant=\"add\")\n",
        "\n",
        "    predicted_return = model.predict(X_today).iloc[0]\n",
        "\n",
        "    if predicted_return > BUY_THRESHOLD:\n",
        "        signal = \"BUY\"\n",
        "    elif predicted_return < SELL_THRESHOLD:\n",
        "        signal = \"SELL\"\n",
        "    else:\n",
        "        signal = \"KEEP\"\n",
        "\n",
        "# =========================\n",
        "# 4. SAXO BANK – CAPITAL & POSITION\n",
        "# =========================\n",
        "\n",
        "cash, currency = get_available_cash()\n",
        "urw_qty = get_urw_position()\n",
        "\n",
        "# =========================\n",
        "# 5. DÉCISION FINALE\n",
        "# =========================\n",
        "\n",
        "decision = \"NO_ACTION\"\n",
        "\n",
        "if signal == \"BUY\" and cash > 500:\n",
        "    decision = \"BUY\"\n",
        "    # place_market_order(\"Buy\", 10)\n",
        "\n",
        "elif signal == \"SELL\" and urw_qty > 0:\n",
        "    decision = \"SELL\"\n",
        "    # place_market_order(\"Sell\", urw_qty)\n",
        "\n",
        "# =========================\n",
        "# 6. SORTIE\n",
        "# =========================\n",
        "\n",
        "print(\"\\n==============================\")\n",
        "print(\"   SIGNAL URW.PA (J+1)\")\n",
        "print(\"==============================\")\n",
        "print(\"Date :\", datetime.now().strftime(\"%Y-%m-%d %H:%M CET\"))\n",
        "print(\"\\nVariations aujourd'hui (%)\")\n",
        "print(returns_today[FEATURES])\n",
        "print(f\"\\nPrévision URW.PA J+1 : {predicted_return:.3f} %\")\n",
        "print(\"Signal modèle       :\", signal)\n",
        "print(\"Capital disponible  :\", cash, currency)\n",
        "print(\"URW.PA détenu       :\", urw_qty)\n",
        "print(\"Décision finale     :\", decision)\n",
        "print(\"==============================\\n\")"
      ],
      "metadata": {
        "id": "9RikQhCXSRQb"
      },
      "id": "9RikQhCXSRQb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect saxo bank"
      ],
      "metadata": {
        "id": "R_gn7zKPNkJh"
      },
      "id": "R_gn7zKPNkJh"
    },
    {
      "cell_type": "code",
      "source": [
        "# test conncetion Saxo bank simulation\n",
        "\n",
        "import requests\n",
        "import json\n",
        "\n",
        "# =========================\n",
        "# CONFIGURATION\n",
        "# =========================\n",
        "\n",
        "ACCESS_TOKEN = \"eyJhbGciOiJFUzI1NiIsIng1dCI6IjY3NEM0MjFEMzZEMUE1OUNFNjFBRTIzMjMyOTVFRTAyRTc3MDMzNTkifQ.eyJvYWEiOiI3Nzc3NSIsImlzcyI6Im9hIiwiYWlkIjoiMTA5IiwidWlkIjoiMWN1NWpOclFzanVKMkY2VXlLYTg5dz09IiwiY2lkIjoiMWN1NWpOclFzanVKMkY2VXlLYTg5dz09IiwiaXNhIjoiRmFsc2UiLCJ0aWQiOiIyMDAyIiwic2lkIjoiMzYwNGFlY2NmYTc3NGNlNmEzNGZmNDIyNGUyZDBmNWEiLCJkZ2kiOiI4NCIsImV4cCI6IjE3Njg4MTEzMjgiLCJvYWwiOiIxRiIsImlpZCI6IjFkNzAzNjg4NzM4MTQzNjMwNGE1MDhkZTRjNTUxOTUwIn0.NuSPihbRVQ_YHoWnW-sQHESQ9QNBExUgGpEM-GaD7gWOQfhr2OU7D4qmgGjhLEW7FNDKsdkL0bRfwf5xuOzftg\"\n",
        "BASE_URL = \"https://gateway.saxobank.com/sim/openapi\"  # ou /sim/openapi\n",
        "SYMBOL = {\"URW.PA\" : \"19099381\"}\n",
        "EXCHANGE = \"Euronext Paris\"\n",
        "\n",
        "HEADERS = {\n",
        "    \"Authorization\": f\"Bearer {ACCESS_TOKEN}\",\n",
        "    \"Accept\" : \"*/*\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "def get_AccountKeys():\n",
        "    url = f\"{BASE_URL}/port/v1/accounts/me\"\n",
        "    response = requests.get(url, headers=HEADERS)\n",
        "    response.raise_for_status()\n",
        "    return response.json()[\"Data\"]\n",
        "\n",
        "def get_Balances(AccountKey):\n",
        "    url = f\"{BASE_URL}/port/v1/balances?AccountKey=\"+AccountKey+\"&ClientKey=\"+AccountKey\n",
        "    response = requests.get(url, headers=HEADERS)\n",
        "    response.raise_for_status()\n",
        "    return response.json()\n",
        "\n",
        "def get_TickerPosition(Uic):\n",
        "    url = f\"{BASE_URL}/trade/v1/infoprices/list?AccountKey=\"+AccountKey+\"&Uics=\"+Uic+\"&AssetType=Stock&Amount=100000&FieldGroups=DisplayAndFormat,Quote\"\n",
        "    response = requests.get(url, headers=HEADERS)\n",
        "    response.raise_for_status()\n",
        "    return response.json()\n",
        "\n",
        "AccountKeys = get_AccountKeys()\n",
        "AccountKey = AccountKeys[0][\"AccountKey\"]\n",
        "Balances = get_Balances(AccountKey)\n",
        "URW = get_TickerPosition(SYMBOL[\"URW.PA\"])\n",
        "print(URW)\n",
        "\n",
        "print(AccountKey)\n",
        "print(Balances)"
      ],
      "metadata": {
        "id": "SWGNJbYASMC1"
      },
      "id": "SWGNJbYASMC1",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}