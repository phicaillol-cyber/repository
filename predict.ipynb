{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phicaillol-cyber/repository/blob/main/predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset creation"
      ],
      "metadata": {
        "id": "c-sdParCMe8G"
      },
      "id": "c-sdParCMe8G"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a59ae70c-0532-4cf6-ac10-38d606068a6e",
      "metadata": {
        "id": "a59ae70c-0532-4cf6-ac10-38d606068a6e",
        "outputId": "ab164713-aa78-46ae-dec3-3a148f3228df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  138 of 138 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variation shape : (1000, 139)\n",
            "Volume shape    : (1001, 139)\n",
            "NaN volume (top 10):\n",
            "Ticker\n",
            "^CIISCSEP    1000\n",
            "000001.SS     335\n",
            "^MOVE         321\n",
            "FISV          317\n",
            "^STOXX50E     317\n",
            "ADBE          316\n",
            "ABBV          316\n",
            "ABT           316\n",
            "ACN           316\n",
            "AAPL          316\n",
            "dtype: int64\n",
            "Creation terminée : 2026-02-12 07:04:15.991318\n"
          ]
        }
      ],
      "source": [
        "### Creation des datasets de VARIATION et de VOLUME des tickers sur 1000 jours\n",
        "### (100 % des tickers conservés, commentaires inclus)\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# ======================================================\n",
        "# PERIODE\n",
        "# ======================================================\n",
        "end_date = datetime.now()\n",
        "start_date = end_date - timedelta(days=1000)\n",
        "\n",
        "# ======================================================\n",
        "# CAC 40\n",
        "# ======================================================\n",
        "cac40_tickers = [\n",
        "    \"AI.PA\",   # Air Liquide\n",
        "    \"AIR.PA\",  # Airbus\n",
        "    \"ALO.PA\",  # Alstom\n",
        "    \"CS.PA\",   # AXA\n",
        "    \"BNP.PA\",  # BNP Paribas\n",
        "    \"EN.PA\",   # Bouygues\n",
        "    \"CAP.PA\",  # Capgemini\n",
        "    \"CA.PA\",   # Carrefour\n",
        "    \"ACA.PA\",  # Crédit Agricole\n",
        "    \"BN.PA\",   # Danone\n",
        "    \"DSY.PA\",  # Dassault Systèmes\n",
        "    \"EDEN.PA\", # Edenred\n",
        "    \"ENGI.PA\", # Engie\n",
        "    \"EL.PA\",   # EssilorLuxottica\n",
        "    \"ERF.PA\",  # Eurofins Scientific\n",
        "    \"RMS.PA\",  # Hermès\n",
        "    \"KER.PA\",  # Kering\n",
        "    \"LR.PA\",   # Legrand\n",
        "    \"OR.PA\",   # L'Oréal\n",
        "    \"MC.PA\",   # LVMH\n",
        "    \"ML.PA\",   # Michelin\n",
        "    \"ORA.PA\",  # Orange\n",
        "    \"RI.PA\",   # Pernod Ricard\n",
        "    \"PUB.PA\",  # Publicis\n",
        "    \"RNO.PA\",  # Renault\n",
        "    \"SAF.PA\",  # Safran\n",
        "    \"SGO.PA\",  # Saint-Gobain\n",
        "    \"SAN.PA\",  # Sanofi\n",
        "    \"SU.PA\",   # Schneider Electric\n",
        "    \"GLE.PA\",  # Société Générale\n",
        "    \"TEP.PA\",  # Teleperformance\n",
        "    \"HO.PA\",   # Thales\n",
        "    \"TTE.PA\",  # TotalEnergies\n",
        "    \"URW.PA\",  # Unibail-Rodamco-Westfield\n",
        "    \"VIE.PA\",  # Veolia\n",
        "    \"DG.PA\",   # Vinci\n",
        "    \"VIV.PA\",  # Vivendi\n",
        "    \"WLN.PA\"   # Worldline\n",
        "]\n",
        "\n",
        "# ======================================================\n",
        "# NASDAQ\n",
        "# ======================================================\n",
        "nasdaq_tickers = [\n",
        "    \"AAPL\",  # Apple\n",
        "    \"MSFT\",  # Microsoft\n",
        "    \"GOOGL\", # Alphabet (Google)\n",
        "    \"AMZN\",  # Amazon\n",
        "    \"META\",  # Meta (Facebook)\n",
        "    \"NVDA\",  # NVIDIA\n",
        "    \"TSLA\",  # Tesla\n",
        "    \"AVGO\",  # Broadcom\n",
        "    \"PEP\",   # PepsiCo\n",
        "    \"COST\",  # Costco\n",
        "    \"ADBE\",  # Adobe\n",
        "    \"NFLX\",  # Netflix\n",
        "    \"PYPL\",  # PayPal\n",
        "    \"INTC\",  # Intel\n",
        "    \"CSCO\",  # Cisco\n",
        "    \"CMCSA\", # Comcast\n",
        "    \"AMGN\",  # Amgen\n",
        "    \"TXN\",   # Texas Instruments\n",
        "    \"QCOM\",  # Qualcomm\n",
        "    \"HON\",   # Honeywell\n",
        "    \"AMD\",   # Advanced Micro Devices\n",
        "    \"ISRG\",  # Intuitive Surgical\n",
        "    \"SBUX\",  # Starbucks\n",
        "    \"MDLZ\",  # Mondelēz\n",
        "    \"AMAT\",  # Applied Materials\n",
        "    \"LRCX\",  # Lam Research\n",
        "    \"ADI\",   # Analog Devices\n",
        "    \"MU\",    # Micron Technology\n",
        "    \"ASML\",  # ASML Holding\n",
        "    \"MRNA\",  # Moderna\n",
        "    \"ILMN\",  # Illumina\n",
        "    \"BKNG\",  # Booking Holdings\n",
        "    \"REGN\",  # Regeneron\n",
        "    \"KDP\",   # Keurig Dr Pepper\n",
        "    \"MNST\",  # Monster Beverage\n",
        "    \"FISV\",  # Fiserv\n",
        "    \"WDAY\",  # Workday\n",
        "    \"TEAM\"   # Atlassian\n",
        "]\n",
        "\n",
        "# ======================================================\n",
        "# NYSE\n",
        "# ======================================================\n",
        "nyse_tickers = [\n",
        "    \"XOM\",   # Exxon Mobil\n",
        "    \"JNJ\",   # Johnson & Johnson\n",
        "    \"V\",     # Visa\n",
        "    \"PG\",    # Procter & Gamble\n",
        "    \"MA\",    # Mastercard\n",
        "    \"HD\",    # Home Depot\n",
        "    \"DIS\",   # Disney\n",
        "    \"VZ\",    # Verizon\n",
        "    \"MCD\",   # McDonald's\n",
        "    \"CVX\",   # Chevron\n",
        "    \"WMT\",   # Walmart\n",
        "    \"BAC\",   # Bank of America\n",
        "    \"PFE\",   # Pfizer\n",
        "    \"KO\",    # Coca-Cola\n",
        "    \"MRK\",   # Merck\n",
        "    \"ABBV\",  # AbbVie\n",
        "    \"CRM\",   # Salesforce\n",
        "    \"ABT\",   # Abbott Laboratories\n",
        "    \"C\",     # Citigroup\n",
        "    \"TMO\",   # Thermo Fisher Scientific\n",
        "    \"LIN\",   # Linde\n",
        "    \"ACN\",   # Accenture\n",
        "    \"CVS\",   # CVS Health\n",
        "    \"ORCL\",  # Oracle\n",
        "    \"NKE\",   # Nike\n",
        "    \"LLY\",   # Eli Lilly\n",
        "    \"DHR\",   # Danaher\n",
        "    \"UNH\",   # UnitedHealth\n",
        "    \"PM\",    # Philip Morris\n",
        "    \"IBM\",   # IBM\n",
        "    \"MMM\",   # 3M\n",
        "    \"MDT\",   # Medtronic\n",
        "    \"GE\",    # General Electric\n",
        "    \"GS\",    # Goldman Sachs\n",
        "    \"CAT\",   # Caterpillar\n",
        "    \"RTX\",   # Raytheon Technologies\n",
        "    \"UPS\",   # UPS\n",
        "    \"MO\"     # Altria\n",
        "]\n",
        "\n",
        "# ======================================================\n",
        "# INDICES & MACRO\n",
        "# ======================================================\n",
        "macro_tickers = [\n",
        "    \"GC=F\",        # Or (Gold)\n",
        "    \"BZ=F\",        # Pétrole Brent\n",
        "    \"^NDX\",        # NASDAQ 100\n",
        "    \"^DJI\",        # Dow Jones\n",
        "    \"^SP500-20\",   # S&P 500 Industrials\n",
        "    \"^SP500-15\",   # S&P 500 Materials\n",
        "    \"^STOXX50E\",   # Euro STOXX 50\n",
        "    \"DX-Y.NYB\",    # Dollar Index (DXY)\n",
        "    \"EUR=X\",       # EUR/USD\n",
        "    \"CHF=X\",       # USD/CHF\n",
        "    \"^VIX\",        # Volatilité\n",
        "    \"^IRX\",        # Taux US 13 semaines\n",
        "    \"^FVX\",        # Taux US 5 ans\n",
        "    \"^TNX\",        # Taux US 10 ans\n",
        "    \"^TYX\",        # Taux US 30 ans\n",
        "    \"^CIISCSEP\",   # Citi Economic Surprise Index\n",
        "    \"^MOVE\",       # Stress crédit\n",
        "    \"BTC-USD\",     # Bitcoin\n",
        "    \"TIP\",         # ETF inflation-linked\n",
        "    \"HYG\",         # Crédit high yield\n",
        "    \"LQD\",         # Crédit investment grade\n",
        "    \"000001.SS\",   # Shanghai Composite\n",
        "    \"FXI\",         # ETF China\n",
        "    \"HG=F\"         # Cuivre\n",
        "]\n",
        "\n",
        "# ======================================================\n",
        "# COMBINAISON TOTALE\n",
        "# ======================================================\n",
        "all_tickers = (\n",
        "    cac40_tickers\n",
        "    + nasdaq_tickers\n",
        "    + nyse_tickers\n",
        "    + macro_tickers\n",
        ")\n",
        "\n",
        "# ======================================================\n",
        "# DOWNLOAD\n",
        "# ======================================================\n",
        "print(\"Downloading data...\")\n",
        "data = yf.download(\n",
        "    all_tickers,\n",
        "    start=start_date,\n",
        "    end=end_date,\n",
        "    auto_adjust=True\n",
        ")\n",
        "\n",
        "# ======================================================\n",
        "# VARIATIONS (%)\n",
        "# ======================================================\n",
        "variation = data[\"Close\"].pct_change(fill_method=None) * 100\n",
        "variation = variation.dropna(how=\"all\")\n",
        "\n",
        "variation.index = pd.to_datetime(variation.index)\n",
        "variation.index.name = \"date\"\n",
        "variation_df = variation.reset_index().sort_values(\"date\")\n",
        "\n",
        "# ======================================================\n",
        "# VOLUMES\n",
        "# ======================================================\n",
        "if \"Volume\" in data.columns:\n",
        "    volume = data[\"Volume\"]\n",
        "else:\n",
        "    volume = pd.DataFrame(index=variation.index)\n",
        "\n",
        "volume.index = pd.to_datetime(volume.index)\n",
        "volume.index.name = \"date\"\n",
        "volume_df = volume.reset_index().sort_values(\"date\")\n",
        "\n",
        "# ======================================================\n",
        "# EXPORT CSV\n",
        "# ======================================================\n",
        "variation_df.to_csv(\"DATASET_1000DAYS_VARIATION.csv\", index=False)\n",
        "volume_df.to_csv(\"DATASET_1000DAYS_VOLUME.csv\", index=False)\n",
        "\n",
        "# ======================================================\n",
        "# LOGS\n",
        "# ======================================================\n",
        "print(\"Variation shape :\", variation_df.shape)\n",
        "print(\"Volume shape    :\", volume_df.shape)\n",
        "print(\"NaN volume (top 10):\")\n",
        "print(volume.isna().sum().sort_values(ascending=False).head(10))\n",
        "print(\"Creation terminée :\", datetime.now())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Methode rules detection avec lag 1-3 jours"
      ],
      "metadata": {
        "id": "uLFG9Y6xVvR1"
      },
      "id": "uLFG9Y6xVvR1"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from itertools import combinations\n",
        "from datetime import datetime\n",
        "\n",
        "# ======================================================\n",
        "# 1. CHARGEMENT DES DONNÉES\n",
        "# ======================================================\n",
        "FILE_VAR = \"DATASET_1000DAYS_VARIATION.csv\"\n",
        "FILE_VOL = \"DATASET_1000DAYS_VOLUME.csv\"\n",
        "\n",
        "df_var = pd.read_csv(FILE_VAR)\n",
        "df_vol = pd.read_csv(FILE_VOL)\n",
        "\n",
        "df_var[\"date\"] = pd.to_datetime(df_var[\"date\"])\n",
        "df_vol[\"date\"] = pd.to_datetime(df_vol[\"date\"])\n",
        "\n",
        "df_var = df_var.set_index(\"date\").sort_index()\n",
        "df_vol = df_vol.set_index(\"date\").sort_index()\n",
        "\n",
        "common_cols = sorted(set(df_var.columns) & set(df_vol.columns))\n",
        "df_var = df_var[common_cols]\n",
        "df_vol = df_vol[common_cols]\n",
        "\n",
        "# ======================================================\n",
        "# 2. DISCRÉTISATION PRIX\n",
        "# ======================================================\n",
        "def discretize_price(x, thr=1.0):\n",
        "    if x > thr:\n",
        "        return \"UP\"\n",
        "    elif x < -thr:\n",
        "        return \"DOWN\"\n",
        "    else:\n",
        "        return \"NEUTRAL\"\n",
        "\n",
        "disc_price = df_var.map(discretize_price)\n",
        "\n",
        "# ======================================================\n",
        "# 3. DISCRÉTISATION VOLUME (Z-SCORE)\n",
        "# ======================================================\n",
        "VOL_WINDOW = 20\n",
        "\n",
        "vol_ma = df_vol.rolling(VOL_WINDOW).mean()\n",
        "vol_std = df_vol.rolling(VOL_WINDOW).std()\n",
        "vol_z = (df_vol - vol_ma) / vol_std\n",
        "\n",
        "def discretize_volume_z(z, thr=0.8):  # seuil légèrement assoupli\n",
        "    if pd.isna(z):\n",
        "        return \"NEUTRAL\"\n",
        "    elif z > thr:\n",
        "        return \"VOL_HIGH\"\n",
        "    elif z < -thr:\n",
        "        return \"VOL_LOW\"\n",
        "    else:\n",
        "        return \"NEUTRAL\"\n",
        "\n",
        "disc_vol = vol_z.map(discretize_volume_z)\n",
        "\n",
        "# ======================================================\n",
        "# 4. PARAMÈTRES AJUSTÉS\n",
        "# ======================================================\n",
        "LEADER_PRICE_STATES = [\"UP\", \"DOWN\"]\n",
        "LEADER_VOL_STATES   = [\"VOL_HIGH\"]\n",
        "TARGET_STATES       = [\"UP\", \"DOWN\"]\n",
        "\n",
        "TRAIN_RATIO = 0.7\n",
        "MIN_OCCURRENCES = 15\n",
        "\n",
        "MIN_SUPPORT = 0.02\n",
        "MIN_CONFIDENCE = 0.55\n",
        "MIN_LIFT = 1.20\n",
        "MAX_CORR = 0.90\n",
        "\n",
        "# ======================================================\n",
        "# 5. SPLIT TRAIN / TEST\n",
        "# ======================================================\n",
        "split_idx = int(len(disc_price) * TRAIN_RATIO)\n",
        "\n",
        "train_price = disc_price.iloc[:split_idx]\n",
        "test_price  = disc_price.iloc[split_idx:]\n",
        "\n",
        "train_vol = disc_vol.iloc[:split_idx]\n",
        "test_vol  = disc_vol.iloc[split_idx:]\n",
        "\n",
        "train_var = df_var.iloc[:split_idx]\n",
        "\n",
        "# ======================================================\n",
        "# 6. MATRICE CORRÉLATION\n",
        "# ======================================================\n",
        "corr_matrix = train_var.corr().abs()\n",
        "\n",
        "# ======================================================\n",
        "# 7. MINING\n",
        "# ======================================================\n",
        "def mine_lead_rules(disc_price, disc_vol):\n",
        "\n",
        "    rules = []\n",
        "    targets = list(disc_price.columns)\n",
        "    n_targets = len(targets)\n",
        "    max_lag = 3\n",
        "\n",
        "    total_iters = n_targets * max_lag\n",
        "    iter_count = 0\n",
        "\n",
        "    for t_idx, target in enumerate(targets, start=1):\n",
        "        for lag in range(1, max_lag + 1):\n",
        "\n",
        "            iter_count += 1\n",
        "            progress = 100 * iter_count / total_iters\n",
        "            now = datetime.now().strftime(\"%H:%M:%S\")\n",
        "\n",
        "            print(\n",
        "                f\"[{now}] \"\n",
        "                f\"[{progress:6.2f}%] \"\n",
        "                f\"Target {t_idx}/{n_targets}: {target} | \"\n",
        "                f\"Lag {lag}/{max_lag}\"\n",
        "            )\n",
        "\n",
        "            future = disc_price[target]\n",
        "            leaders_p = disc_price.shift(lag)\n",
        "            leaders_v = disc_vol.shift(lag)\n",
        "\n",
        "            future = future.iloc[lag:]\n",
        "            leaders_p = leaders_p.iloc[lag:]\n",
        "            leaders_v = leaders_v.iloc[lag:]\n",
        "\n",
        "            leaders = [c for c in targets if c != target]\n",
        "\n",
        "            for l1, l2 in combinations(leaders, 2):\n",
        "\n",
        "                if corr_matrix.loc[l1, l2] > MAX_CORR:\n",
        "                    continue\n",
        "\n",
        "                for s1 in LEADER_PRICE_STATES:\n",
        "                    for s2 in LEADER_PRICE_STATES:\n",
        "                        for v1 in LEADER_VOL_STATES:\n",
        "                            for v2 in LEADER_VOL_STATES:\n",
        "\n",
        "                                mask = (\n",
        "                                    (leaders_p[l1] == s1) &\n",
        "                                    (leaders_p[l2] == s2) &\n",
        "                                    (leaders_v[l1] == v1) &\n",
        "                                    (leaders_v[l2] == v2)\n",
        "                                )\n",
        "\n",
        "                                occurrences = mask.sum()\n",
        "                                if occurrences < MIN_OCCURRENCES:\n",
        "                                    continue\n",
        "\n",
        "                                support = mask.mean()\n",
        "                                if support < MIN_SUPPORT:\n",
        "                                    continue\n",
        "\n",
        "                                for target_state in TARGET_STATES:\n",
        "\n",
        "                                    base_rate = (future == target_state).mean()\n",
        "                                    if base_rate == 0:\n",
        "                                        continue\n",
        "\n",
        "                                    confidence = (future[mask] == target_state).mean()\n",
        "                                    if confidence < MIN_CONFIDENCE:\n",
        "                                        continue\n",
        "\n",
        "                                    lift = confidence / base_rate\n",
        "                                    if lift < MIN_LIFT:\n",
        "                                        continue\n",
        "\n",
        "                                    rules.append({\n",
        "                                        \"target\": target,\n",
        "                                        \"target_direction\": target_state,\n",
        "                                        \"leader_1\": l1,\n",
        "                                        \"leader_2\": l2,\n",
        "                                        \"lag_days\": lag,\n",
        "                                        \"support\": round(support, 3),\n",
        "                                        \"confidence\": round(confidence, 3),\n",
        "                                        \"lift\": round(lift, 2),\n",
        "                                        \"occurrences\": int(occurrences)\n",
        "                                    })\n",
        "\n",
        "    return pd.DataFrame(rules)\n",
        "\n",
        "# ======================================================\n",
        "# 8. MINING TRAIN\n",
        "# ======================================================\n",
        "rules_train = mine_lead_rules(train_price, train_vol)\n",
        "\n",
        "print(\"\\nNombre règles train :\", len(rules_train))\n",
        "\n",
        "# ======================================================\n",
        "# 9. VALIDATION TEST\n",
        "# ======================================================\n",
        "def validate_rules(rules_df):\n",
        "\n",
        "    if rules_df.empty:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for _, row in rules_df.iterrows():\n",
        "\n",
        "        lag = row[\"lag_days\"]\n",
        "        target = row[\"target\"]\n",
        "        target_state = row[\"target_direction\"]\n",
        "\n",
        "        future = test_price[target]\n",
        "        leaders_p = test_price.shift(lag)\n",
        "        leaders_v = test_vol.shift(lag)\n",
        "\n",
        "        future = future.iloc[lag:]\n",
        "        leaders_p = leaders_p.iloc[lag:]\n",
        "        leaders_v = leaders_v.iloc[lag:]\n",
        "\n",
        "        mask = (\n",
        "            (leaders_p[row[\"leader_1\"]] == \"UP\") &\n",
        "            (leaders_p[row[\"leader_2\"]] == \"UP\") &\n",
        "            (leaders_v[row[\"leader_1\"]] == \"VOL_HIGH\") &\n",
        "            (leaders_v[row[\"leader_2\"]] == \"VOL_HIGH\")\n",
        "        )\n",
        "\n",
        "        if mask.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        confidence_test = (future[mask] == target_state).mean()\n",
        "        base_rate = (future == target_state).mean()\n",
        "        lift_test = confidence_test / base_rate if base_rate > 0 else 0\n",
        "\n",
        "        row_result = row.to_dict()\n",
        "        row_result[\"test_confidence\"] = round(confidence_test, 3)\n",
        "        row_result[\"test_lift\"] = round(lift_test, 2)\n",
        "\n",
        "        results.append(row_result)\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "rules_final = validate_rules(rules_train)\n",
        "\n",
        "# ======================================================\n",
        "# 10. TRI & EXPORT\n",
        "# ======================================================\n",
        "if rules_final.empty:\n",
        "    print(\"\\n⚠️ Aucune règle valide trouvée.\")\n",
        "else:\n",
        "    rules_final = rules_final.sort_values(\n",
        "        by=[\"test_lift\", \"lift\"],\n",
        "        ascending=False\n",
        "    )\n",
        "\n",
        "    rules_final.to_csv(\n",
        "        \"lead_lag_rules_more_rules.csv\",\n",
        "        index=False\n",
        "    )\n",
        "\n",
        "    print(\"\\nTop 20 règles validées :\\n\")\n",
        "    print(rules_final.head(20))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulxQ3yK6AiaM",
        "outputId": "1bf1cb85-591d-4a30-c246-d3e8a50bb07c"
      },
      "id": "ulxQ3yK6AiaM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07:05:06] [  0.24%] Target 1/138: 000001.SS | Lag 1/3\n",
            "[07:06:35] [  0.48%] Target 1/138: 000001.SS | Lag 2/3\n",
            "[07:08:03] [  0.72%] Target 1/138: 000001.SS | Lag 3/3\n",
            "[07:09:31] [  0.97%] Target 2/138: AAPL | Lag 1/3\n",
            "[07:11:09] [  1.21%] Target 2/138: AAPL | Lag 2/3\n",
            "[07:12:39] [  1.45%] Target 2/138: AAPL | Lag 3/3\n",
            "[07:14:08] [  1.69%] Target 3/138: ABBV | Lag 1/3\n",
            "[07:15:36] [  1.93%] Target 3/138: ABBV | Lag 2/3\n",
            "[07:17:04] [  2.17%] Target 3/138: ABBV | Lag 3/3\n",
            "[07:18:32] [  2.42%] Target 4/138: ABT | Lag 1/3\n",
            "[07:20:00] [  2.66%] Target 4/138: ABT | Lag 2/3\n",
            "[07:21:28] [  2.90%] Target 4/138: ABT | Lag 3/3\n",
            "[07:22:55] [  3.14%] Target 5/138: ACA.PA | Lag 1/3\n",
            "[07:24:22] [  3.38%] Target 5/138: ACA.PA | Lag 2/3\n",
            "[07:25:50] [  3.62%] Target 5/138: ACA.PA | Lag 3/3\n",
            "[07:27:16] [  3.86%] Target 6/138: ACN | Lag 1/3\n",
            "[07:28:44] [  4.11%] Target 6/138: ACN | Lag 2/3\n",
            "[07:30:13] [  4.35%] Target 6/138: ACN | Lag 3/3\n",
            "[07:31:42] [  4.59%] Target 7/138: ADBE | Lag 1/3\n",
            "[07:33:12] [  4.83%] Target 7/138: ADBE | Lag 2/3\n",
            "[07:34:41] [  5.07%] Target 7/138: ADBE | Lag 3/3\n",
            "[07:36:08] [  5.31%] Target 8/138: ADI | Lag 1/3\n",
            "[07:37:36] [  5.56%] Target 8/138: ADI | Lag 2/3\n",
            "[07:39:04] [  5.80%] Target 8/138: ADI | Lag 3/3\n",
            "[07:40:32] [  6.04%] Target 9/138: AI.PA | Lag 1/3\n",
            "[07:41:59] [  6.28%] Target 9/138: AI.PA | Lag 2/3\n",
            "[07:43:28] [  6.52%] Target 9/138: AI.PA | Lag 3/3\n",
            "[07:44:56] [  6.76%] Target 10/138: AIR.PA | Lag 1/3\n",
            "[07:46:25] [  7.00%] Target 10/138: AIR.PA | Lag 2/3\n",
            "[07:47:53] [  7.25%] Target 10/138: AIR.PA | Lag 3/3\n",
            "[07:49:21] [  7.49%] Target 11/138: ALO.PA | Lag 1/3\n",
            "[07:50:48] [  7.73%] Target 11/138: ALO.PA | Lag 2/3\n",
            "[07:52:15] [  7.97%] Target 11/138: ALO.PA | Lag 3/3\n",
            "[07:53:42] [  8.21%] Target 12/138: AMAT | Lag 1/3\n",
            "[07:55:10] [  8.45%] Target 12/138: AMAT | Lag 2/3\n",
            "[07:56:38] [  8.70%] Target 12/138: AMAT | Lag 3/3\n",
            "[07:58:05] [  8.94%] Target 13/138: AMD | Lag 1/3\n",
            "[07:59:33] [  9.18%] Target 13/138: AMD | Lag 2/3\n",
            "[08:01:02] [  9.42%] Target 13/138: AMD | Lag 3/3\n",
            "[08:02:33] [  9.66%] Target 14/138: AMGN | Lag 1/3\n",
            "[08:04:03] [  9.90%] Target 14/138: AMGN | Lag 2/3\n",
            "[08:05:31] [ 10.14%] Target 14/138: AMGN | Lag 3/3\n",
            "[08:07:01] [ 10.39%] Target 15/138: AMZN | Lag 1/3\n",
            "[08:08:27] [ 10.63%] Target 15/138: AMZN | Lag 2/3\n",
            "[08:09:54] [ 10.87%] Target 15/138: AMZN | Lag 3/3\n",
            "[08:11:22] [ 11.11%] Target 16/138: ASML | Lag 1/3\n",
            "[08:12:49] [ 11.35%] Target 16/138: ASML | Lag 2/3\n",
            "[08:14:17] [ 11.59%] Target 16/138: ASML | Lag 3/3\n",
            "[08:15:44] [ 11.84%] Target 17/138: AVGO | Lag 1/3\n",
            "[08:17:12] [ 12.08%] Target 17/138: AVGO | Lag 2/3\n",
            "[08:18:40] [ 12.32%] Target 17/138: AVGO | Lag 3/3\n",
            "[08:20:07] [ 12.56%] Target 18/138: BAC | Lag 1/3\n",
            "[08:21:34] [ 12.80%] Target 18/138: BAC | Lag 2/3\n",
            "[08:23:02] [ 13.04%] Target 18/138: BAC | Lag 3/3\n",
            "[08:24:28] [ 13.29%] Target 19/138: BKNG | Lag 1/3\n",
            "[08:25:54] [ 13.53%] Target 19/138: BKNG | Lag 2/3\n",
            "[08:27:21] [ 13.77%] Target 19/138: BKNG | Lag 3/3\n",
            "[08:28:48] [ 14.01%] Target 20/138: BN.PA | Lag 1/3\n",
            "[08:30:14] [ 14.25%] Target 20/138: BN.PA | Lag 2/3\n",
            "[08:31:40] [ 14.49%] Target 20/138: BN.PA | Lag 3/3\n",
            "[08:33:07] [ 14.73%] Target 21/138: BNP.PA | Lag 1/3\n",
            "[08:34:37] [ 14.98%] Target 21/138: BNP.PA | Lag 2/3\n",
            "[08:36:04] [ 15.22%] Target 21/138: BNP.PA | Lag 3/3\n",
            "[08:37:31] [ 15.46%] Target 22/138: BTC-USD | Lag 1/3\n",
            "[08:38:57] [ 15.70%] Target 22/138: BTC-USD | Lag 2/3\n",
            "[08:40:23] [ 15.94%] Target 22/138: BTC-USD | Lag 3/3\n",
            "[08:41:50] [ 16.18%] Target 23/138: BZ=F | Lag 1/3\n",
            "[08:43:17] [ 16.43%] Target 23/138: BZ=F | Lag 2/3\n",
            "[08:44:44] [ 16.67%] Target 23/138: BZ=F | Lag 3/3\n",
            "[08:46:10] [ 16.91%] Target 24/138: C | Lag 1/3\n",
            "[08:47:37] [ 17.15%] Target 24/138: C | Lag 2/3\n",
            "[08:49:05] [ 17.39%] Target 24/138: C | Lag 3/3\n",
            "[08:50:33] [ 17.63%] Target 25/138: CA.PA | Lag 1/3\n",
            "[08:52:02] [ 17.87%] Target 25/138: CA.PA | Lag 2/3\n",
            "[08:53:28] [ 18.12%] Target 25/138: CA.PA | Lag 3/3\n",
            "[08:54:54] [ 18.36%] Target 26/138: CAP.PA | Lag 1/3\n",
            "[08:56:21] [ 18.60%] Target 26/138: CAP.PA | Lag 2/3\n",
            "[08:57:47] [ 18.84%] Target 26/138: CAP.PA | Lag 3/3\n",
            "[08:59:14] [ 19.08%] Target 27/138: CAT | Lag 1/3\n",
            "[09:00:46] [ 19.32%] Target 27/138: CAT | Lag 2/3\n",
            "[09:02:15] [ 19.57%] Target 27/138: CAT | Lag 3/3\n",
            "[09:03:43] [ 19.81%] Target 28/138: CHF=X | Lag 1/3\n",
            "[09:05:12] [ 20.05%] Target 28/138: CHF=X | Lag 2/3\n",
            "[09:06:39] [ 20.29%] Target 28/138: CHF=X | Lag 3/3\n",
            "[09:08:07] [ 20.53%] Target 29/138: CMCSA | Lag 1/3\n",
            "[09:09:34] [ 20.77%] Target 29/138: CMCSA | Lag 2/3\n",
            "[09:11:02] [ 21.01%] Target 29/138: CMCSA | Lag 3/3\n",
            "[09:12:29] [ 21.26%] Target 30/138: COST | Lag 1/3\n",
            "[09:13:56] [ 21.50%] Target 30/138: COST | Lag 2/3\n",
            "[09:15:24] [ 21.74%] Target 30/138: COST | Lag 3/3\n",
            "[09:16:52] [ 21.98%] Target 31/138: CRM | Lag 1/3\n",
            "[09:18:22] [ 22.22%] Target 31/138: CRM | Lag 2/3\n",
            "[09:19:50] [ 22.46%] Target 31/138: CRM | Lag 3/3\n",
            "[09:21:18] [ 22.71%] Target 32/138: CS.PA | Lag 1/3\n",
            "[09:22:45] [ 22.95%] Target 32/138: CS.PA | Lag 2/3\n",
            "[09:24:11] [ 23.19%] Target 32/138: CS.PA | Lag 3/3\n",
            "[09:25:39] [ 23.43%] Target 33/138: CSCO | Lag 1/3\n",
            "[09:27:06] [ 23.67%] Target 33/138: CSCO | Lag 2/3\n",
            "[09:28:32] [ 23.91%] Target 33/138: CSCO | Lag 3/3\n",
            "[09:29:59] [ 24.15%] Target 34/138: CVS | Lag 1/3\n",
            "[09:31:27] [ 24.40%] Target 34/138: CVS | Lag 2/3\n",
            "[09:32:52] [ 24.64%] Target 34/138: CVS | Lag 3/3\n",
            "[09:34:18] [ 24.88%] Target 35/138: CVX | Lag 1/3\n",
            "[09:35:45] [ 25.12%] Target 35/138: CVX | Lag 2/3\n",
            "[09:37:12] [ 25.36%] Target 35/138: CVX | Lag 3/3\n",
            "[09:38:39] [ 25.60%] Target 36/138: DG.PA | Lag 1/3\n",
            "[09:40:06] [ 25.85%] Target 36/138: DG.PA | Lag 2/3\n",
            "[09:41:33] [ 26.09%] Target 36/138: DG.PA | Lag 3/3\n",
            "[09:43:00] [ 26.33%] Target 37/138: DHR | Lag 1/3\n",
            "[09:44:26] [ 26.57%] Target 37/138: DHR | Lag 2/3\n",
            "[09:45:53] [ 26.81%] Target 37/138: DHR | Lag 3/3\n",
            "[09:47:19] [ 27.05%] Target 38/138: DIS | Lag 1/3\n",
            "[09:48:46] [ 27.29%] Target 38/138: DIS | Lag 2/3\n",
            "[09:50:13] [ 27.54%] Target 38/138: DIS | Lag 3/3\n",
            "[09:51:40] [ 27.78%] Target 39/138: DSY.PA | Lag 1/3\n",
            "[09:53:06] [ 28.02%] Target 39/138: DSY.PA | Lag 2/3\n",
            "[09:54:31] [ 28.26%] Target 39/138: DSY.PA | Lag 3/3\n",
            "[09:55:58] [ 28.50%] Target 40/138: DX-Y.NYB | Lag 1/3\n",
            "[09:57:24] [ 28.74%] Target 40/138: DX-Y.NYB | Lag 2/3\n",
            "[09:58:51] [ 28.99%] Target 40/138: DX-Y.NYB | Lag 3/3\n",
            "[10:00:17] [ 29.23%] Target 41/138: EDEN.PA | Lag 1/3\n",
            "[10:01:43] [ 29.47%] Target 41/138: EDEN.PA | Lag 2/3\n",
            "[10:03:11] [ 29.71%] Target 41/138: EDEN.PA | Lag 3/3\n",
            "[10:04:38] [ 29.95%] Target 42/138: EL.PA | Lag 1/3\n",
            "[10:06:04] [ 30.19%] Target 42/138: EL.PA | Lag 2/3\n",
            "[10:07:31] [ 30.43%] Target 42/138: EL.PA | Lag 3/3\n",
            "[10:08:59] [ 30.68%] Target 43/138: EN.PA | Lag 1/3\n",
            "[10:10:27] [ 30.92%] Target 43/138: EN.PA | Lag 2/3\n",
            "[10:11:56] [ 31.16%] Target 43/138: EN.PA | Lag 3/3\n",
            "[10:13:23] [ 31.40%] Target 44/138: ENGI.PA | Lag 1/3\n",
            "[10:14:52] [ 31.64%] Target 44/138: ENGI.PA | Lag 2/3\n",
            "[10:16:22] [ 31.88%] Target 44/138: ENGI.PA | Lag 3/3\n",
            "[10:17:49] [ 32.13%] Target 45/138: ERF.PA | Lag 1/3\n",
            "[10:19:16] [ 32.37%] Target 45/138: ERF.PA | Lag 2/3\n",
            "[10:20:43] [ 32.61%] Target 45/138: ERF.PA | Lag 3/3\n",
            "[10:22:10] [ 32.85%] Target 46/138: EUR=X | Lag 1/3\n",
            "[10:23:37] [ 33.09%] Target 46/138: EUR=X | Lag 2/3\n",
            "[10:25:03] [ 33.33%] Target 46/138: EUR=X | Lag 3/3\n",
            "[10:26:30] [ 33.57%] Target 47/138: FISV | Lag 1/3\n",
            "[10:27:56] [ 33.82%] Target 47/138: FISV | Lag 2/3\n",
            "[10:29:22] [ 34.06%] Target 47/138: FISV | Lag 3/3\n",
            "[10:30:46] [ 34.30%] Target 48/138: FXI | Lag 1/3\n",
            "[10:32:12] [ 34.54%] Target 48/138: FXI | Lag 2/3\n",
            "[10:33:38] [ 34.78%] Target 48/138: FXI | Lag 3/3\n",
            "[10:35:05] [ 35.02%] Target 49/138: GC=F | Lag 1/3\n",
            "[10:36:33] [ 35.27%] Target 49/138: GC=F | Lag 2/3\n",
            "[10:38:00] [ 35.51%] Target 49/138: GC=F | Lag 3/3\n",
            "[10:39:25] [ 35.75%] Target 50/138: GE | Lag 1/3\n",
            "[10:40:53] [ 35.99%] Target 50/138: GE | Lag 2/3\n",
            "[10:42:21] [ 36.23%] Target 50/138: GE | Lag 3/3\n",
            "[10:43:49] [ 36.47%] Target 51/138: GLE.PA | Lag 1/3\n",
            "[10:45:15] [ 36.71%] Target 51/138: GLE.PA | Lag 2/3\n",
            "[10:46:42] [ 36.96%] Target 51/138: GLE.PA | Lag 3/3\n",
            "[10:48:08] [ 37.20%] Target 52/138: GOOGL | Lag 1/3\n",
            "[10:49:35] [ 37.44%] Target 52/138: GOOGL | Lag 2/3\n",
            "[10:51:02] [ 37.68%] Target 52/138: GOOGL | Lag 3/3\n",
            "[10:52:29] [ 37.92%] Target 53/138: GS | Lag 1/3\n",
            "[10:53:56] [ 38.16%] Target 53/138: GS | Lag 2/3\n",
            "[10:55:23] [ 38.41%] Target 53/138: GS | Lag 3/3\n",
            "[10:56:51] [ 38.65%] Target 54/138: HD | Lag 1/3\n",
            "[10:58:19] [ 38.89%] Target 54/138: HD | Lag 2/3\n",
            "[10:59:47] [ 39.13%] Target 54/138: HD | Lag 3/3\n",
            "[11:01:15] [ 39.37%] Target 55/138: HG=F | Lag 1/3\n",
            "[11:02:43] [ 39.61%] Target 55/138: HG=F | Lag 2/3\n",
            "[11:04:10] [ 39.86%] Target 55/138: HG=F | Lag 3/3\n",
            "[11:05:36] [ 40.10%] Target 56/138: HO.PA | Lag 1/3\n",
            "[11:07:05] [ 40.34%] Target 56/138: HO.PA | Lag 2/3\n",
            "[11:08:33] [ 40.58%] Target 56/138: HO.PA | Lag 3/3\n",
            "[11:09:59] [ 40.82%] Target 57/138: HON | Lag 1/3\n",
            "[11:11:25] [ 41.06%] Target 57/138: HON | Lag 2/3\n",
            "[11:12:53] [ 41.30%] Target 57/138: HON | Lag 3/3\n",
            "[11:14:20] [ 41.55%] Target 58/138: HYG | Lag 1/3\n",
            "[11:15:45] [ 41.79%] Target 58/138: HYG | Lag 2/3\n",
            "[11:17:10] [ 42.03%] Target 58/138: HYG | Lag 3/3\n",
            "[11:18:37] [ 42.27%] Target 59/138: IBM | Lag 1/3\n",
            "[11:20:04] [ 42.51%] Target 59/138: IBM | Lag 2/3\n",
            "[11:21:31] [ 42.75%] Target 59/138: IBM | Lag 3/3\n",
            "[11:23:02] [ 43.00%] Target 60/138: ILMN | Lag 1/3\n",
            "[11:24:29] [ 43.24%] Target 60/138: ILMN | Lag 2/3\n",
            "[11:25:56] [ 43.48%] Target 60/138: ILMN | Lag 3/3\n",
            "[11:27:24] [ 43.72%] Target 61/138: INTC | Lag 1/3\n",
            "[11:28:51] [ 43.96%] Target 61/138: INTC | Lag 2/3\n",
            "[11:30:19] [ 44.20%] Target 61/138: INTC | Lag 3/3\n",
            "[11:31:48] [ 44.44%] Target 62/138: ISRG | Lag 1/3\n",
            "[11:33:16] [ 44.69%] Target 62/138: ISRG | Lag 2/3\n",
            "[11:34:44] [ 44.93%] Target 62/138: ISRG | Lag 3/3\n",
            "[11:36:13] [ 45.17%] Target 63/138: JNJ | Lag 1/3\n",
            "[11:37:40] [ 45.41%] Target 63/138: JNJ | Lag 2/3\n",
            "[11:39:08] [ 45.65%] Target 63/138: JNJ | Lag 3/3\n",
            "[11:40:36] [ 45.89%] Target 64/138: KDP | Lag 1/3\n",
            "[11:42:03] [ 46.14%] Target 64/138: KDP | Lag 2/3\n",
            "[11:43:30] [ 46.38%] Target 64/138: KDP | Lag 3/3\n",
            "[11:44:58] [ 46.62%] Target 65/138: KER.PA | Lag 1/3\n",
            "[11:46:25] [ 46.86%] Target 65/138: KER.PA | Lag 2/3\n",
            "[11:47:53] [ 47.10%] Target 65/138: KER.PA | Lag 3/3\n",
            "[11:49:22] [ 47.34%] Target 66/138: KO | Lag 1/3\n",
            "[11:50:50] [ 47.58%] Target 66/138: KO | Lag 2/3\n",
            "[11:52:19] [ 47.83%] Target 66/138: KO | Lag 3/3\n",
            "[11:53:47] [ 48.07%] Target 67/138: LIN | Lag 1/3\n",
            "[11:55:15] [ 48.31%] Target 67/138: LIN | Lag 2/3\n",
            "[11:56:42] [ 48.55%] Target 67/138: LIN | Lag 3/3\n",
            "[11:58:09] [ 48.79%] Target 68/138: LLY | Lag 1/3\n",
            "[11:59:37] [ 49.03%] Target 68/138: LLY | Lag 2/3\n",
            "[12:01:05] [ 49.28%] Target 68/138: LLY | Lag 3/3\n",
            "[12:02:33] [ 49.52%] Target 69/138: LQD | Lag 1/3\n",
            "[12:04:03] [ 49.76%] Target 69/138: LQD | Lag 2/3\n",
            "[12:05:31] [ 50.00%] Target 69/138: LQD | Lag 3/3\n",
            "[12:06:59] [ 50.24%] Target 70/138: LR.PA | Lag 1/3\n",
            "[12:08:27] [ 50.48%] Target 70/138: LR.PA | Lag 2/3\n",
            "[12:09:55] [ 50.72%] Target 70/138: LR.PA | Lag 3/3\n",
            "[12:11:23] [ 50.97%] Target 71/138: LRCX | Lag 1/3\n",
            "[12:12:51] [ 51.21%] Target 71/138: LRCX | Lag 2/3\n",
            "[12:14:19] [ 51.45%] Target 71/138: LRCX | Lag 3/3\n",
            "[12:15:47] [ 51.69%] Target 72/138: MA | Lag 1/3\n",
            "[12:17:15] [ 51.93%] Target 72/138: MA | Lag 2/3\n",
            "[12:18:42] [ 52.17%] Target 72/138: MA | Lag 3/3\n",
            "[12:20:08] [ 52.42%] Target 73/138: MC.PA | Lag 1/3\n",
            "[12:21:34] [ 52.66%] Target 73/138: MC.PA | Lag 2/3\n",
            "[12:23:02] [ 52.90%] Target 73/138: MC.PA | Lag 3/3\n",
            "[12:24:28] [ 53.14%] Target 74/138: MCD | Lag 1/3\n",
            "[12:25:54] [ 53.38%] Target 74/138: MCD | Lag 2/3\n",
            "[12:27:20] [ 53.62%] Target 74/138: MCD | Lag 3/3\n",
            "[12:28:47] [ 53.86%] Target 75/138: MDLZ | Lag 1/3\n",
            "[12:30:13] [ 54.11%] Target 75/138: MDLZ | Lag 2/3\n",
            "[12:31:42] [ 54.35%] Target 75/138: MDLZ | Lag 3/3\n",
            "[12:33:09] [ 54.59%] Target 76/138: MDT | Lag 1/3\n",
            "[12:34:36] [ 54.83%] Target 76/138: MDT | Lag 2/3\n",
            "[12:36:03] [ 55.07%] Target 76/138: MDT | Lag 3/3\n",
            "[12:37:30] [ 55.31%] Target 77/138: META | Lag 1/3\n",
            "[12:38:56] [ 55.56%] Target 77/138: META | Lag 2/3\n",
            "[12:40:22] [ 55.80%] Target 77/138: META | Lag 3/3\n",
            "[12:41:48] [ 56.04%] Target 78/138: ML.PA | Lag 1/3\n",
            "[12:43:16] [ 56.28%] Target 78/138: ML.PA | Lag 2/3\n",
            "[12:44:44] [ 56.52%] Target 78/138: ML.PA | Lag 3/3\n",
            "[12:46:10] [ 56.76%] Target 79/138: MMM | Lag 1/3\n",
            "[12:47:37] [ 57.00%] Target 79/138: MMM | Lag 2/3\n",
            "[12:49:04] [ 57.25%] Target 79/138: MMM | Lag 3/3\n",
            "[12:50:30] [ 57.49%] Target 80/138: MNST | Lag 1/3\n",
            "[12:51:55] [ 57.73%] Target 80/138: MNST | Lag 2/3\n",
            "[12:53:22] [ 57.97%] Target 80/138: MNST | Lag 3/3\n",
            "[12:54:49] [ 58.21%] Target 81/138: MO | Lag 1/3\n",
            "[12:56:15] [ 58.45%] Target 81/138: MO | Lag 2/3\n",
            "[12:57:41] [ 58.70%] Target 81/138: MO | Lag 3/3\n",
            "[12:59:07] [ 58.94%] Target 82/138: MRK | Lag 1/3\n",
            "[13:00:33] [ 59.18%] Target 82/138: MRK | Lag 2/3\n",
            "[13:02:00] [ 59.42%] Target 82/138: MRK | Lag 3/3\n",
            "[13:03:27] [ 59.66%] Target 83/138: MRNA | Lag 1/3\n",
            "[13:04:53] [ 59.90%] Target 83/138: MRNA | Lag 2/3\n",
            "[13:06:18] [ 60.14%] Target 83/138: MRNA | Lag 3/3\n",
            "[13:07:45] [ 60.39%] Target 84/138: MSFT | Lag 1/3\n",
            "[13:09:12] [ 60.63%] Target 84/138: MSFT | Lag 2/3\n",
            "[13:10:42] [ 60.87%] Target 84/138: MSFT | Lag 3/3\n",
            "[13:12:10] [ 61.11%] Target 85/138: MU | Lag 1/3\n",
            "[13:13:38] [ 61.35%] Target 85/138: MU | Lag 2/3\n",
            "[13:15:06] [ 61.59%] Target 85/138: MU | Lag 3/3\n",
            "[13:16:36] [ 61.84%] Target 86/138: NFLX | Lag 1/3\n",
            "[13:18:04] [ 62.08%] Target 86/138: NFLX | Lag 2/3\n",
            "[13:19:31] [ 62.32%] Target 86/138: NFLX | Lag 3/3\n",
            "[13:20:59] [ 62.56%] Target 87/138: NKE | Lag 1/3\n",
            "[13:22:27] [ 62.80%] Target 87/138: NKE | Lag 2/3\n",
            "[13:23:54] [ 63.04%] Target 87/138: NKE | Lag 3/3\n",
            "[13:25:20] [ 63.29%] Target 88/138: NVDA | Lag 1/3\n",
            "[13:26:46] [ 63.53%] Target 88/138: NVDA | Lag 2/3\n",
            "[13:28:12] [ 63.77%] Target 88/138: NVDA | Lag 3/3\n",
            "[13:29:39] [ 64.01%] Target 89/138: OR.PA | Lag 1/3\n",
            "[13:31:06] [ 64.25%] Target 89/138: OR.PA | Lag 2/3\n",
            "[13:32:34] [ 64.49%] Target 89/138: OR.PA | Lag 3/3\n",
            "[13:34:02] [ 64.73%] Target 90/138: ORA.PA | Lag 1/3\n",
            "[13:35:29] [ 64.98%] Target 90/138: ORA.PA | Lag 2/3\n",
            "[13:36:56] [ 65.22%] Target 90/138: ORA.PA | Lag 3/3\n",
            "[13:38:23] [ 65.46%] Target 91/138: ORCL | Lag 1/3\n",
            "[13:39:53] [ 65.70%] Target 91/138: ORCL | Lag 2/3\n",
            "[13:41:22] [ 65.94%] Target 91/138: ORCL | Lag 3/3\n",
            "[13:42:49] [ 66.18%] Target 92/138: PEP | Lag 1/3\n",
            "[13:44:15] [ 66.43%] Target 92/138: PEP | Lag 2/3\n",
            "[13:45:41] [ 66.67%] Target 92/138: PEP | Lag 3/3\n",
            "[13:47:08] [ 66.91%] Target 93/138: PFE | Lag 1/3\n",
            "[13:48:36] [ 67.15%] Target 93/138: PFE | Lag 2/3\n",
            "[13:50:04] [ 67.39%] Target 93/138: PFE | Lag 3/3\n",
            "[13:51:32] [ 67.63%] Target 94/138: PG | Lag 1/3\n",
            "[13:52:59] [ 67.87%] Target 94/138: PG | Lag 2/3\n",
            "[13:54:26] [ 68.12%] Target 94/138: PG | Lag 3/3\n",
            "[13:55:54] [ 68.36%] Target 95/138: PM | Lag 1/3\n",
            "[13:57:22] [ 68.60%] Target 95/138: PM | Lag 2/3\n",
            "[13:58:50] [ 68.84%] Target 95/138: PM | Lag 3/3\n",
            "[14:00:17] [ 69.08%] Target 96/138: PUB.PA | Lag 1/3\n",
            "[14:01:45] [ 69.32%] Target 96/138: PUB.PA | Lag 2/3\n",
            "[14:03:13] [ 69.57%] Target 96/138: PUB.PA | Lag 3/3\n",
            "[14:04:41] [ 69.81%] Target 97/138: PYPL | Lag 1/3\n",
            "[14:06:08] [ 70.05%] Target 97/138: PYPL | Lag 2/3\n",
            "[14:07:42] [ 70.29%] Target 97/138: PYPL | Lag 3/3\n",
            "[14:09:12] [ 70.53%] Target 98/138: QCOM | Lag 1/3\n",
            "[14:10:40] [ 70.77%] Target 98/138: QCOM | Lag 2/3\n",
            "[14:12:08] [ 71.01%] Target 98/138: QCOM | Lag 3/3\n",
            "[14:13:38] [ 71.26%] Target 99/138: REGN | Lag 1/3\n",
            "[14:15:07] [ 71.50%] Target 99/138: REGN | Lag 2/3\n",
            "[14:16:36] [ 71.74%] Target 99/138: REGN | Lag 3/3\n",
            "[14:18:03] [ 71.98%] Target 100/138: RI.PA | Lag 1/3\n",
            "[14:19:30] [ 72.22%] Target 100/138: RI.PA | Lag 2/3\n",
            "[14:20:57] [ 72.46%] Target 100/138: RI.PA | Lag 3/3\n",
            "[14:22:25] [ 72.71%] Target 101/138: RMS.PA | Lag 1/3\n",
            "[14:23:53] [ 72.95%] Target 101/138: RMS.PA | Lag 2/3\n",
            "[14:25:22] [ 73.19%] Target 101/138: RMS.PA | Lag 3/3\n",
            "[14:26:52] [ 73.43%] Target 102/138: RNO.PA | Lag 1/3\n",
            "[14:28:19] [ 73.67%] Target 102/138: RNO.PA | Lag 2/3\n",
            "[14:29:45] [ 73.91%] Target 102/138: RNO.PA | Lag 3/3\n",
            "[14:31:11] [ 74.15%] Target 103/138: RTX | Lag 1/3\n",
            "[14:32:38] [ 74.40%] Target 103/138: RTX | Lag 2/3\n",
            "[14:34:06] [ 74.64%] Target 103/138: RTX | Lag 3/3\n",
            "[14:35:37] [ 74.88%] Target 104/138: SAF.PA | Lag 1/3\n",
            "[14:37:06] [ 75.12%] Target 104/138: SAF.PA | Lag 2/3\n",
            "[14:38:35] [ 75.36%] Target 104/138: SAF.PA | Lag 3/3\n",
            "[14:40:03] [ 75.60%] Target 105/138: SAN.PA | Lag 1/3\n",
            "[14:41:31] [ 75.85%] Target 105/138: SAN.PA | Lag 2/3\n",
            "[14:42:58] [ 76.09%] Target 105/138: SAN.PA | Lag 3/3\n",
            "[14:44:25] [ 76.33%] Target 106/138: SBUX | Lag 1/3\n",
            "[14:45:53] [ 76.57%] Target 106/138: SBUX | Lag 2/3\n",
            "[14:47:21] [ 76.81%] Target 106/138: SBUX | Lag 3/3\n",
            "[14:48:49] [ 77.05%] Target 107/138: SGO.PA | Lag 1/3\n",
            "[14:50:18] [ 77.29%] Target 107/138: SGO.PA | Lag 2/3\n",
            "[14:51:46] [ 77.54%] Target 107/138: SGO.PA | Lag 3/3\n",
            "[14:53:14] [ 77.78%] Target 108/138: SU.PA | Lag 1/3\n",
            "[14:54:43] [ 78.02%] Target 108/138: SU.PA | Lag 2/3\n",
            "[14:56:13] [ 78.26%] Target 108/138: SU.PA | Lag 3/3\n",
            "[14:57:42] [ 78.50%] Target 109/138: TEAM | Lag 1/3\n",
            "[14:59:11] [ 78.74%] Target 109/138: TEAM | Lag 2/3\n",
            "[15:00:39] [ 78.99%] Target 109/138: TEAM | Lag 3/3\n",
            "[15:02:12] [ 79.23%] Target 110/138: TEP.PA | Lag 1/3\n",
            "[15:03:44] [ 79.47%] Target 110/138: TEP.PA | Lag 2/3\n",
            "[15:05:12] [ 79.71%] Target 110/138: TEP.PA | Lag 3/3\n",
            "[15:06:41] [ 79.95%] Target 111/138: TIP | Lag 1/3\n",
            "[15:08:08] [ 80.19%] Target 111/138: TIP | Lag 2/3\n",
            "[15:09:36] [ 80.43%] Target 111/138: TIP | Lag 3/3\n",
            "[15:11:04] [ 80.68%] Target 112/138: TMO | Lag 1/3\n",
            "[15:12:32] [ 80.92%] Target 112/138: TMO | Lag 2/3\n",
            "[15:14:02] [ 81.16%] Target 112/138: TMO | Lag 3/3\n",
            "[15:15:29] [ 81.40%] Target 113/138: TSLA | Lag 1/3\n",
            "[15:16:57] [ 81.64%] Target 113/138: TSLA | Lag 2/3\n",
            "[15:18:24] [ 81.88%] Target 113/138: TSLA | Lag 3/3\n",
            "[15:19:52] [ 82.13%] Target 114/138: TTE.PA | Lag 1/3\n",
            "[15:21:19] [ 82.37%] Target 114/138: TTE.PA | Lag 2/3\n",
            "[15:22:46] [ 82.61%] Target 114/138: TTE.PA | Lag 3/3\n",
            "[15:24:12] [ 82.85%] Target 115/138: TXN | Lag 1/3\n",
            "[15:25:39] [ 83.09%] Target 115/138: TXN | Lag 2/3\n",
            "[15:27:05] [ 83.33%] Target 115/138: TXN | Lag 3/3\n",
            "[15:28:31] [ 83.57%] Target 116/138: UNH | Lag 1/3\n",
            "[15:29:58] [ 83.82%] Target 116/138: UNH | Lag 2/3\n",
            "[15:31:25] [ 84.06%] Target 116/138: UNH | Lag 3/3\n",
            "[15:32:53] [ 84.30%] Target 117/138: UPS | Lag 1/3\n",
            "[15:34:23] [ 84.54%] Target 117/138: UPS | Lag 2/3\n",
            "[15:35:50] [ 84.78%] Target 117/138: UPS | Lag 3/3\n",
            "[15:37:19] [ 85.02%] Target 118/138: URW.PA | Lag 1/3\n",
            "[15:38:46] [ 85.27%] Target 118/138: URW.PA | Lag 2/3\n",
            "[15:40:12] [ 85.51%] Target 118/138: URW.PA | Lag 3/3\n",
            "[15:41:38] [ 85.75%] Target 119/138: V | Lag 1/3\n",
            "[15:43:04] [ 85.99%] Target 119/138: V | Lag 2/3\n",
            "[15:44:31] [ 86.23%] Target 119/138: V | Lag 3/3\n",
            "[15:45:57] [ 86.47%] Target 120/138: VIE.PA | Lag 1/3\n",
            "[15:47:24] [ 86.71%] Target 120/138: VIE.PA | Lag 2/3\n",
            "[15:48:52] [ 86.96%] Target 120/138: VIE.PA | Lag 3/3\n",
            "[15:50:19] [ 87.20%] Target 121/138: VIV.PA | Lag 1/3\n",
            "[15:51:45] [ 87.44%] Target 121/138: VIV.PA | Lag 2/3\n",
            "[15:53:12] [ 87.68%] Target 121/138: VIV.PA | Lag 3/3\n",
            "[15:54:38] [ 87.92%] Target 122/138: VZ | Lag 1/3\n",
            "[15:56:05] [ 88.16%] Target 122/138: VZ | Lag 2/3\n",
            "[15:57:31] [ 88.41%] Target 122/138: VZ | Lag 3/3\n",
            "[15:59:00] [ 88.65%] Target 123/138: WDAY | Lag 1/3\n",
            "[16:00:28] [ 88.89%] Target 123/138: WDAY | Lag 2/3\n",
            "[16:01:57] [ 89.13%] Target 123/138: WDAY | Lag 3/3\n",
            "[16:03:25] [ 89.37%] Target 124/138: WLN.PA | Lag 1/3\n",
            "[16:04:53] [ 89.61%] Target 124/138: WLN.PA | Lag 2/3\n",
            "[16:06:20] [ 89.86%] Target 124/138: WLN.PA | Lag 3/3\n",
            "[16:07:48] [ 90.10%] Target 125/138: WMT | Lag 1/3\n",
            "[16:09:17] [ 90.34%] Target 125/138: WMT | Lag 2/3\n",
            "[16:10:47] [ 90.58%] Target 125/138: WMT | Lag 3/3\n",
            "[16:12:15] [ 90.82%] Target 126/138: XOM | Lag 1/3\n",
            "[16:13:42] [ 91.06%] Target 126/138: XOM | Lag 2/3\n",
            "[16:15:09] [ 91.30%] Target 126/138: XOM | Lag 3/3\n",
            "[16:16:37] [ 91.55%] Target 127/138: ^CIISCSEP | Lag 1/3\n",
            "[16:18:04] [ 91.79%] Target 127/138: ^CIISCSEP | Lag 2/3\n",
            "[16:19:31] [ 92.03%] Target 127/138: ^CIISCSEP | Lag 3/3\n",
            "[16:21:00] [ 92.27%] Target 128/138: ^DJI | Lag 1/3\n",
            "[16:22:29] [ 92.51%] Target 128/138: ^DJI | Lag 2/3\n",
            "[16:23:56] [ 92.75%] Target 128/138: ^DJI | Lag 3/3\n",
            "[16:25:22] [ 93.00%] Target 129/138: ^FVX | Lag 1/3\n",
            "[16:26:50] [ 93.24%] Target 129/138: ^FVX | Lag 2/3\n",
            "[16:28:16] [ 93.48%] Target 129/138: ^FVX | Lag 3/3\n",
            "[16:29:43] [ 93.72%] Target 130/138: ^IRX | Lag 1/3\n",
            "[16:31:11] [ 93.96%] Target 130/138: ^IRX | Lag 2/3\n",
            "[16:32:37] [ 94.20%] Target 130/138: ^IRX | Lag 3/3\n",
            "[16:34:05] [ 94.44%] Target 131/138: ^MOVE | Lag 1/3\n",
            "[16:35:32] [ 94.69%] Target 131/138: ^MOVE | Lag 2/3\n",
            "[16:37:00] [ 94.93%] Target 131/138: ^MOVE | Lag 3/3\n",
            "[16:38:27] [ 95.17%] Target 132/138: ^NDX | Lag 1/3\n",
            "[16:39:54] [ 95.41%] Target 132/138: ^NDX | Lag 2/3\n",
            "[16:41:21] [ 95.65%] Target 132/138: ^NDX | Lag 3/3\n",
            "[16:42:48] [ 95.89%] Target 133/138: ^SP500-15 | Lag 1/3\n",
            "[16:44:16] [ 96.14%] Target 133/138: ^SP500-15 | Lag 2/3\n",
            "[16:45:43] [ 96.38%] Target 133/138: ^SP500-15 | Lag 3/3\n",
            "[16:47:10] [ 96.62%] Target 134/138: ^SP500-20 | Lag 1/3\n",
            "[16:48:37] [ 96.86%] Target 134/138: ^SP500-20 | Lag 2/3\n",
            "[16:50:04] [ 97.10%] Target 134/138: ^SP500-20 | Lag 3/3\n",
            "[16:51:30] [ 97.34%] Target 135/138: ^STOXX50E | Lag 1/3\n",
            "[16:52:57] [ 97.58%] Target 135/138: ^STOXX50E | Lag 2/3\n",
            "[16:54:23] [ 97.83%] Target 135/138: ^STOXX50E | Lag 3/3\n",
            "[16:55:49] [ 98.07%] Target 136/138: ^TNX | Lag 1/3\n",
            "[16:57:16] [ 98.31%] Target 136/138: ^TNX | Lag 2/3\n",
            "[16:58:44] [ 98.55%] Target 136/138: ^TNX | Lag 3/3\n",
            "[17:00:11] [ 98.79%] Target 137/138: ^TYX | Lag 1/3\n",
            "[17:01:39] [ 99.03%] Target 137/138: ^TYX | Lag 2/3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Script hybride v3"
      ],
      "metadata": {
        "id": "gunL1Xi-r_XF"
      },
      "id": "gunL1Xi-r_XF"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from itertools import combinations\n",
        "from datetime import datetime\n",
        "\n",
        "# ======================================================\n",
        "# 1. CHARGEMENT\n",
        "# ======================================================\n",
        "FILE_VAR = \"DATASET_1000DAYS_VARIATION.csv\"\n",
        "FILE_VOL = \"DATASET_1000DAYS_VOLUME.csv\"\n",
        "\n",
        "df_var = pd.read_csv(FILE_VAR)\n",
        "df_vol = pd.read_csv(FILE_VOL)\n",
        "\n",
        "df_var[\"date\"] = pd.to_datetime(df_var[\"date\"])\n",
        "df_vol[\"date\"] = pd.to_datetime(df_vol[\"date\"])\n",
        "\n",
        "df_var = df_var.set_index(\"date\").sort_index()\n",
        "df_vol = df_vol.set_index(\"date\").sort_index()\n",
        "\n",
        "common_cols = sorted(set(df_var.columns) & set(df_vol.columns))\n",
        "df_var = df_var[common_cols]\n",
        "df_vol = df_vol[common_cols]\n",
        "\n",
        "# ======================================================\n",
        "# 2. DISCRÉTISATION PRIX\n",
        "# ======================================================\n",
        "def discretize_price(x, thr=1.0):\n",
        "    if x > thr:\n",
        "        return \"UP\"\n",
        "    elif x < -thr:\n",
        "        return \"DOWN\"\n",
        "    return \"NEUTRAL\"\n",
        "\n",
        "disc_price = df_var.map(discretize_price)\n",
        "\n",
        "# ======================================================\n",
        "# 3. DISCRÉTISATION VOLUME (Z-score)\n",
        "# ======================================================\n",
        "VOL_WINDOW = 20\n",
        "vol_ma = df_vol.rolling(VOL_WINDOW).mean()\n",
        "vol_std = df_vol.rolling(VOL_WINDOW).std()\n",
        "vol_z = (df_vol - vol_ma) / vol_std\n",
        "\n",
        "def discretize_volume_z(z, thr=0.9):\n",
        "    if pd.isna(z):\n",
        "        return \"NEUTRAL\"\n",
        "    elif z > thr:\n",
        "        return \"VOL_HIGH\"\n",
        "    elif z < -thr:\n",
        "        return \"VOL_LOW\"\n",
        "    return \"NEUTRAL\"\n",
        "\n",
        "disc_vol = vol_z.map(discretize_volume_z)\n",
        "\n",
        "# ======================================================\n",
        "# 4. PARAMÈTRES HYBRIDES\n",
        "# ======================================================\n",
        "TRAIN_RATIO = 0.7\n",
        "MIN_OCCURRENCES = 20\n",
        "MIN_SUPPORT = 0.025\n",
        "MIN_CONFIDENCE = 0.57\n",
        "MIN_LIFT = 1.25\n",
        "MAX_CORR = 0.88\n",
        "Z_THRESHOLD = 2.0\n",
        "\n",
        "LEADER_PRICE_STATES = [\"UP\", \"DOWN\"]\n",
        "LEADER_VOL_STATES = [\"VOL_HIGH\"]\n",
        "TARGET_STATES = [\"UP\", \"DOWN\"]\n",
        "\n",
        "# ======================================================\n",
        "# 5. SPLIT TRAIN / TEST\n",
        "# ======================================================\n",
        "split_idx = int(len(disc_price) * TRAIN_RATIO)\n",
        "\n",
        "train_price = disc_price.iloc[:split_idx]\n",
        "test_price  = disc_price.iloc[split_idx:]\n",
        "\n",
        "train_vol = disc_vol.iloc[:split_idx]\n",
        "test_vol  = disc_vol.iloc[split_idx:]\n",
        "\n",
        "train_var = df_var.iloc[:split_idx]\n",
        "corr_matrix = train_var.corr().abs()\n",
        "\n",
        "# ======================================================\n",
        "# 6. MINING V3\n",
        "# ======================================================\n",
        "def mine_rules():\n",
        "\n",
        "    rules = []\n",
        "    targets = list(train_price.columns)\n",
        "    n_targets = len(targets)\n",
        "    max_lag = 3\n",
        "    total_iters = n_targets * max_lag\n",
        "    iter_count = 0\n",
        "\n",
        "    for t_idx, target in enumerate(targets, 1):\n",
        "        for lag in range(1, max_lag + 1):\n",
        "\n",
        "            iter_count += 1\n",
        "            progress = 100 * iter_count / total_iters\n",
        "            now = datetime.now().strftime(\"%H:%M:%S\")\n",
        "\n",
        "            print(\n",
        "                f\"[{now}] \"\n",
        "                f\"[{progress:6.2f}%] \"\n",
        "                f\"Target {t_idx}/{n_targets}: {target} | \"\n",
        "                f\"Lag {lag}/{max_lag}\"\n",
        "            )\n",
        "\n",
        "            future = train_price[target]\n",
        "            leaders_p = train_price.shift(lag)\n",
        "            leaders_v = train_vol.shift(lag)\n",
        "\n",
        "            future = future.iloc[lag:]\n",
        "            leaders_p = leaders_p.iloc[lag:]\n",
        "            leaders_v = leaders_v.iloc[lag:]\n",
        "\n",
        "            leaders = [c for c in targets if c != target]\n",
        "\n",
        "            for l1, l2 in combinations(leaders, 2):\n",
        "\n",
        "                if corr_matrix.loc[l1, l2] > MAX_CORR:\n",
        "                    continue\n",
        "\n",
        "                for s1 in LEADER_PRICE_STATES:\n",
        "                    for s2 in LEADER_PRICE_STATES:\n",
        "                        for v1 in LEADER_VOL_STATES:\n",
        "                            for v2 in LEADER_VOL_STATES:\n",
        "\n",
        "                                mask = (\n",
        "                                    (leaders_p[l1] == s1) &\n",
        "                                    (leaders_p[l2] == s2) &\n",
        "                                    (leaders_v[l1] == v1) &\n",
        "                                    (leaders_v[l2] == v2)\n",
        "                                )\n",
        "\n",
        "                                n = mask.sum()\n",
        "                                if n < MIN_OCCURRENCES:\n",
        "                                    continue\n",
        "\n",
        "                                support = mask.mean()\n",
        "                                if support < MIN_SUPPORT:\n",
        "                                    continue\n",
        "\n",
        "                                for target_state in TARGET_STATES:\n",
        "\n",
        "                                    base_rate = (future == target_state).mean()\n",
        "                                    if base_rate == 0:\n",
        "                                        continue\n",
        "\n",
        "                                    confidence = (future[mask] == target_state).mean()\n",
        "                                    lift = confidence / base_rate\n",
        "\n",
        "                                    if confidence < MIN_CONFIDENCE:\n",
        "                                        continue\n",
        "                                    if lift < MIN_LIFT:\n",
        "                                        continue\n",
        "\n",
        "                                    # 🔬 Z-score binomial\n",
        "                                    std = np.sqrt(base_rate * (1 - base_rate) / n)\n",
        "                                    if std == 0:\n",
        "                                        continue\n",
        "\n",
        "                                    z_score = (confidence - base_rate) / std\n",
        "\n",
        "                                    if z_score < Z_THRESHOLD:\n",
        "                                        continue\n",
        "\n",
        "                                    rules.append({\n",
        "                                        \"target\": target,\n",
        "                                        \"leader_1\": l1,\n",
        "                                        \"leader_2\": l2,\n",
        "                                        \"lag\": lag,\n",
        "                                        \"support\": round(support,3),\n",
        "                                        \"confidence\": round(confidence,3),\n",
        "                                        \"lift\": round(lift,2),\n",
        "                                        \"z_score\": round(z_score,2),\n",
        "                                        \"occurrences\": int(n)\n",
        "                                    })\n",
        "\n",
        "    return pd.DataFrame(rules)\n",
        "\n",
        "# ======================================================\n",
        "# 7. MINING\n",
        "# ======================================================\n",
        "rules_train = mine_rules()\n",
        "\n",
        "if rules_train.empty:\n",
        "    print(\"\\n⚠️ Aucune règle trouvée en TRAIN.\")\n",
        "else:\n",
        "    print(\"\\nRègles train :\", len(rules_train))\n",
        "\n",
        "# ======================================================\n",
        "# 8. VALIDATION OOS\n",
        "# ======================================================\n",
        "def validate_rules(rules_df):\n",
        "\n",
        "    if rules_df.empty:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for _, row in rules_df.iterrows():\n",
        "\n",
        "        lag = row[\"lag\"]\n",
        "        target = row[\"target\"]\n",
        "\n",
        "        future = test_price[target]\n",
        "        leaders_p = test_price.shift(lag)\n",
        "\n",
        "        future = future.iloc[lag:]\n",
        "        leaders_p = leaders_p.iloc[lag:]\n",
        "\n",
        "        mask = (\n",
        "            (leaders_p[row[\"leader_1\"]] == \"UP\") &\n",
        "            (leaders_p[row[\"leader_2\"]] == \"UP\")\n",
        "        )\n",
        "\n",
        "        if mask.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        confidence_test = (future[mask] == \"UP\").mean()\n",
        "        base_rate = (future == \"UP\").mean()\n",
        "        lift_test = confidence_test / base_rate if base_rate > 0 else 0\n",
        "\n",
        "        r = row.to_dict()\n",
        "        r[\"test_lift\"] = round(lift_test,2)\n",
        "        r[\"test_confidence\"] = round(confidence_test,3)\n",
        "\n",
        "        results.append(r)\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "rules_final = validate_rules(rules_train)\n",
        "\n",
        "# ======================================================\n",
        "# 9. TRI & EXPORT SÉCURISÉ\n",
        "# ======================================================\n",
        "if rules_final.empty:\n",
        "    print(\"\\n⚠️ Aucune règle valide en OOS.\")\n",
        "else:\n",
        "    rules_final = rules_final.sort_values(\n",
        "        by=[\"test_lift\",\"z_score\"],\n",
        "        ascending=False\n",
        "    )\n",
        "\n",
        "    rules_final.to_csv(\"lead_lag_rules_V3_hybrid.csv\", index=False)\n",
        "\n",
        "    print(\"\\nTop 20 règles V3 :\\n\")\n",
        "    print(rules_final.head(20))\n"
      ],
      "metadata": {
        "id": "xnT4xOXUsD8v"
      },
      "id": "xnT4xOXUsD8v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Génération des features à partir des règles"
      ],
      "metadata": {
        "id": "OHG0YnIhPrtO"
      },
      "id": "OHG0YnIhPrtO"
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# AUTO-GENERATE ONE FEATURES CSV PER TARGET TICKER\n",
        "# ======================================================\n",
        "\n",
        "import os\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ======================================================\n",
        "# CLEAN OUTPUT\n",
        "# ======================================================\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"pandas\")\n",
        "pd.set_option(\"future.no_silent_downcasting\", True)\n",
        "\n",
        "# ======================================================\n",
        "# FILES\n",
        "# ======================================================\n",
        "RULES_FILE = \"lead_lag_rules_exhaustive_2leaders.csv\"\n",
        "DATA_FILE  = \"DATASET_1000DAYS_VARIATION.csv\"\n",
        "OUTPUT_DIR = \"features_by_target\"\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "def load_csv(filename):\n",
        "    if os.path.exists(filename):\n",
        "        return pd.read_csv(filename)\n",
        "    if os.path.exists(f\"/mnt/data/{filename}\"):\n",
        "        return pd.read_csv(f\"/mnt/data/{filename}\")\n",
        "    raise FileNotFoundError(filename)\n",
        "\n",
        "# ======================================================\n",
        "# LOAD DATA\n",
        "# ======================================================\n",
        "rules = load_csv(RULES_FILE)\n",
        "df    = load_csv(DATA_FILE)\n",
        "\n",
        "# ======================================================\n",
        "# DATA PREP\n",
        "# ======================================================\n",
        "df.iloc[:, 0] = pd.to_datetime(df.iloc[:, 0])\n",
        "df = df.set_index(df.columns[0]).sort_index()\n",
        "df = df.apply(pd.to_numeric, errors=\"coerce\")\n",
        "\n",
        "# ======================================================\n",
        "# HELPERS\n",
        "# ======================================================\n",
        "def state_condition(series: pd.Series, state: str) -> pd.Series:\n",
        "    if state == \"UP\":\n",
        "        return series > 0\n",
        "    if state == \"DOWN\":\n",
        "        return series < 0\n",
        "    raise ValueError(state)\n",
        "\n",
        "# ======================================================\n",
        "# FEATURE ENGINEERING (ONCE)\n",
        "# ======================================================\n",
        "feature_dict = {}\n",
        "\n",
        "for idx, rule in rules.iterrows():\n",
        "\n",
        "    try:\n",
        "        lag = int(rule[\"lag_days\"])\n",
        "        direction = 1 if rule[\"target_direction\"] == \"UP\" else -1\n",
        "\n",
        "        leaders = [\n",
        "            (rule[\"leader_1\"], rule[\"leader_1_state\"]),\n",
        "            (rule[\"leader_2\"], rule[\"leader_2_state\"]),\n",
        "        ]\n",
        "\n",
        "        support    = float(rule[\"support\"])\n",
        "        confidence = float(rule[\"confidence\"])\n",
        "        lift       = float(rule[\"lift\"])\n",
        "\n",
        "        fname = f\"rule_{idx}_{leaders[0][0]}_{leaders[1][0]}_lag{lag}\"\n",
        "\n",
        "        conds = [\n",
        "            state_condition(df[leader], state)\n",
        "            for leader, state in leaders\n",
        "        ]\n",
        "\n",
        "        rule_active = conds[0] & conds[1]\n",
        "        rule_active = (\n",
        "            rule_active\n",
        "            .shift(lag)\n",
        "            .astype(\"boolean\")\n",
        "            .fillna(False)\n",
        "        )\n",
        "\n",
        "        bin_feat = rule_active.astype(\"int8\")\n",
        "\n",
        "        feature_dict[fname] = bin_feat\n",
        "        feature_dict[f\"{fname}_w\"] = (\n",
        "            bin_feat * confidence * np.log1p(support) * lift\n",
        "        ).astype(\"float32\")\n",
        "        feature_dict[f\"{fname}_dir\"] = (\n",
        "            bin_feat * direction\n",
        "        ).astype(\"int8\")\n",
        "\n",
        "    except KeyError:\n",
        "        continue\n",
        "\n",
        "# ======================================================\n",
        "# BUILD BASE FEATURES DF (SHARED)\n",
        "# ======================================================\n",
        "base_features = pd.concat(\n",
        "    list(feature_dict.values()),\n",
        "    axis=1\n",
        ")\n",
        "base_features.columns = list(feature_dict.keys())\n",
        "base_features = base_features.copy()\n",
        "base_features = base_features.fillna(0)\n",
        "\n",
        "# ======================================================\n",
        "# EXPORT ONE CSV PER TARGET\n",
        "# ======================================================\n",
        "HORIZON = 1\n",
        "targets = sorted(rules[\"target\"].unique())\n",
        "\n",
        "print(f\"📊 Targets found: {targets}\")\n",
        "\n",
        "for target in targets:\n",
        "\n",
        "    if target not in df.columns:\n",
        "        print(f\"⚠️ Target {target} not in dataset — skipped\")\n",
        "        continue\n",
        "\n",
        "    features = base_features.copy()\n",
        "\n",
        "    features[\"target\"] = (\n",
        "        df[target]\n",
        "        .shift(-HORIZON)\n",
        "        .astype(\"float32\")\n",
        "    )\n",
        "\n",
        "    features[\"target_ticker\"] = target\n",
        "\n",
        "    # Rule-based signal (optional)\n",
        "    features[\"signal_score\"] = (\n",
        "        features.filter(like=\"_dir\").sum(axis=1)\n",
        "    ).astype(\"int16\")\n",
        "\n",
        "    features[\"signal\"] = np.sign(features[\"signal_score\"]).astype(\"int8\")\n",
        "\n",
        "    # Reorder columns (human-friendly)\n",
        "    ordered_cols = (\n",
        "        [\"target_ticker\"]\n",
        "        + [c for c in features.columns if c != \"target_ticker\"]\n",
        "    )\n",
        "    features = features[ordered_cols]\n",
        "\n",
        "    # Export\n",
        "    out_path = os.path.join(\n",
        "        OUTPUT_DIR,\n",
        "        f\"features_{target}.csv\"\n",
        "    )\n",
        "\n",
        "    features.to_csv(out_path, index_label=\"date\")\n",
        "\n",
        "    print(f\"✅ Exported: {out_path} | shape={features.shape}\")\n",
        "\n",
        "print(\"🎯 All targets exported.\")\n"
      ],
      "metadata": {
        "id": "4_Tj7NPgZwOh"
      },
      "id": "4_Tj7NPgZwOh",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}